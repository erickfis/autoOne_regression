<!DOCTYPE html>
<html >
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
      <title>Linear regression - sklearn</title>
    
      <link rel="stylesheet" href="_static/pygments.css">
      <link rel="stylesheet" href="_static/theme.css">
      <link rel="stylesheet" href="_static/sphinx_press_theme.css">
      
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>

      <!-- sphinx script_files -->
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>

      
      <script src="_static/theme-vendors.js"></script>
      <script src="_static/theme.js" defer></script>
    
  <link rel="index" title="Index" href="genindex.html" />
  <link rel="search" title="Search" href="search.html" />
  <link rel="next" title="Modeling with machine learning" href="05-machine.html" />
  <link rel="prev" title="Linear regression - OLS Model" href="03-ols.html" /> 
  </head>

  <body>
    <div id="app" class="theme-container" :class="pageClasses"><navbar @toggle-sidebar="toggleSidebar">
  <router-link to="index.html" class="home-link">
    
      <span class="site-name">AutoOne Regression</span>
    
  </router-link>

  <div class="links">
    <navlinks class="can-hide">



    </navlinks>
  </div>
</navbar>

      
      <div class="sidebar-mask" @click="toggleSidebar(false)">
      </div>
        <sidebar @toggle-sidebar="toggleSidebar">
          
          <navlinks>
            



            
          </navlinks><div id="searchbox" class="searchbox" role="search">
  <div class="caption"><span class="caption-text">Quick search</span>
    <div class="searchformwrapper">
      <form class="search" action="search.html" method="get">
        <input type="text" name="q" />
        <input type="submit" value="Search" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div><div class="sidebar-links" role="navigation" aria-label="main navigation">
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="index.html#autoone-price-prediction">Contents:</a></span>
      </p>
      <ul class="current">
        
          <li class="toctree-l1 "><a href="01-cleaning.html" class="reference internal ">Data cleaning</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="02-analysis.html" class="reference internal ">Exploratory data analysis - features</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="02-analysis-price.html" class="reference internal ">Exploratory data analysis - price</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="03-ols.html" class="reference internal ">Linear regression - OLS Model</a>

            
          </li>

        
          <li class="toctree-l1 current"><a href="#" class="reference internal current">Linear regression - sklearn</a>

            
              <ul>
                
                  <li class="toctree-l2"><a href="#Feature-selection" class="reference internal">Feature selection</a></li>
                
                  <li class="toctree-l2"><a href="#Normalization-and-encoding-of-features" class="reference internal">Normalization and encoding of features</a></li>
                
                  <li class="toctree-l2"><a href="#Hyper-parameter-tuning-and-Cross-Validation" class="reference internal">Hyper-parameter tuning and Cross Validation</a></li>
                
                  <li class="toctree-l2"><a href="#Linear-regression-model" class="reference internal">Linear regression model</a></li>
                
                  <li class="toctree-l2"><a href="#Regularized-models---Ridge-regularization" class="reference internal">Regularized models - Ridge regularization</a></li>
                
                  <li class="toctree-l2"><a href="#Regularized-models---Lasso" class="reference internal">Regularized models - Lasso</a></li>
                
                  <li class="toctree-l2"><a href="#Huber-Regressor" class="reference internal">Huber Regressor</a></li>
                
                  <li class="toctree-l2"><a href="#Comparing-models---MSE-and-R^2" class="reference internal">Comparing models - MSE and R^2</a></li>
                
                  <li class="toctree-l2"><a href="#Most-important-features" class="reference internal">Most important features</a></li>
                
                  <li class="toctree-l2"><a href="#Comparing-the-models---conclusions" class="reference internal">Comparing the models - conclusions</a></li>
                
              </ul>
            
          </li>

        
          <li class="toctree-l1 "><a href="05-machine.html" class="reference internal ">Modeling with machine learning</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="06-scripts.html" class="reference internal ">Python scripts</a>

            
          </li>

        
      </ul>
    </div>
  
</div>
        </sidebar>

      <page>
          <div class="body-header" role="navigation" aria-label="navigation">
  
  <ul class="breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
    
    <li>Linear regression - sklearn</li>
  </ul>
  

  <ul class="page-nav">
  <li class="prev">
    <a href="03-ols.html"
       title="previous chapter">← Linear regression - OLS Model</a>
  </li>
  <li class="next">
    <a href="05-machine.html"
       title="next chapter">Modeling with machine learning →</a>
  </li>
</ul>
  
</div>
<hr>
          <div class="content" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Linear-regression---sklearn">
<h1>Linear regression - sklearn<a class="headerlink" href="#Linear-regression---sklearn" title="Permalink to this headline">¶</a></h1>
<p>In this section, we will cover:</p>
<ul class="simple">
<li><p>fitting different linear regression models with sklearn</p></li>
<li><p>normalization and encoding of features</p></li>
<li><p>score analysis: MSE and variance explained: <span class="math notranslate nohighlight">\(R^2\)</span></p></li>
<li><p>residual analysis</p></li>
<li><p>most important features</p></li>
<li><p>comparing the models: conclusions</p></li>
</ul>
<div class="section" id="Feature-selection">
<h2>Feature selection<a class="headerlink" href="#Feature-selection" title="Permalink to this headline">¶</a></h2>
<p>This time we will not be manually selecting features. Some sklearn linear regressor models uses regularization, and that should address the lack of feature selection.</p>
<p>This has an important consequence, however: we will be using all features, even the ones which are not linearly correlated with the outcome. This means we will be trying to fit a linear model on a case that may be not strictly linear.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>import pandas as pd
import numpy as np

df = pd.read_csv(&#39;data/df_resample.csv&#39;)
df.head()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>make</th>
      <th>fuel_type</th>
      <th>aspiration</th>
      <th>num_of_doors</th>
      <th>body_style</th>
      <th>drive_wheels</th>
      <th>engine_location</th>
      <th>wheel_base</th>
      <th>length</th>
      <th>...</th>
      <th>engine_size</th>
      <th>fuel_system</th>
      <th>bore</th>
      <th>stroke</th>
      <th>compression_ratio</th>
      <th>horsepower</th>
      <th>peak_rpm</th>
      <th>city_mpg</th>
      <th>highway_mpg</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>nissan</td>
      <td>gas</td>
      <td>std</td>
      <td>four</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>97.2</td>
      <td>173.4</td>
      <td>...</td>
      <td>120</td>
      <td>2bbl</td>
      <td>3.33</td>
      <td>3.47</td>
      <td>8.5</td>
      <td>97.0</td>
      <td>5200.0</td>
      <td>27</td>
      <td>34</td>
      <td>9549.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>volkswagen</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>hatchback</td>
      <td>fwd</td>
      <td>front</td>
      <td>94.5</td>
      <td>165.7</td>
      <td>...</td>
      <td>109</td>
      <td>mpfi</td>
      <td>3.19</td>
      <td>3.40</td>
      <td>8.5</td>
      <td>90.0</td>
      <td>5500.0</td>
      <td>24</td>
      <td>29</td>
      <td>9980.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>bmw</td>
      <td>gas</td>
      <td>std</td>
      <td>four</td>
      <td>sedan</td>
      <td>rwd</td>
      <td>front</td>
      <td>103.5</td>
      <td>189.0</td>
      <td>...</td>
      <td>164</td>
      <td>mpfi</td>
      <td>3.31</td>
      <td>3.19</td>
      <td>9.0</td>
      <td>121.0</td>
      <td>4250.0</td>
      <td>20</td>
      <td>25</td>
      <td>24565.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>subaru</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>hatchback</td>
      <td>fwd</td>
      <td>front</td>
      <td>93.7</td>
      <td>156.9</td>
      <td>...</td>
      <td>97</td>
      <td>2bbl</td>
      <td>3.62</td>
      <td>2.36</td>
      <td>9.0</td>
      <td>69.0</td>
      <td>4900.0</td>
      <td>31</td>
      <td>36</td>
      <td>5118.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>mazda</td>
      <td>diesel</td>
      <td>std</td>
      <td>four</td>
      <td>sedan</td>
      <td>rwd</td>
      <td>front</td>
      <td>104.9</td>
      <td>175.0</td>
      <td>...</td>
      <td>134</td>
      <td>idi</td>
      <td>3.43</td>
      <td>3.64</td>
      <td>22.0</td>
      <td>72.0</td>
      <td>4200.0</td>
      <td>31</td>
      <td>39</td>
      <td>18344.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 25 columns</p>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>X = df.copy()
X.drop(&#39;price&#39;, axis=1, inplace=True)
y = np.log(df.price) # as discussed, we are going to use the log transform here

## Train-test split#
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=.3, random_state=95276
)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Normalization-and-encoding-of-features">
<h2>Normalization and encoding of features<a class="headerlink" href="#Normalization-and-encoding-of-features" title="Permalink to this headline">¶</a></h2>
<p>The range of the numeric features varies a lot for each one of them:</p>
<ul class="simple">
<li><p>bore range: ~2</p></li>
<li><p>curb range: ~3500</p></li>
</ul>
<p>Also, its easy to see that they are measuring completely different things and therefore are in different scales.</p>
<p>In order to properly fit linear regression models with regularization, we must account for those differences.</p>
<p>Also, it is import to encode the categories, like fuel-type, to sklearn can use them.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.preprocessing import OneHotEncoder, StandardScaler
import pickle

with open(&#39;data/category_list&#39;, &#39;rb&#39;) as file:
    cat_cols = pickle.load(file)

# numeric columns
num_cols = [col for col in X_train.columns if col not in cat_cols]

# normalize numeric features
scaler = StandardScaler()
num_scaled = scaler.fit_transform(X_train[num_cols])

# encode categories
encoder = OneHotEncoder(sparse=False)
cat_encoded = encoder.fit_transform(X_train[cat_cols])

# all together
X_train_proc = np.concatenate([cat_encoded, num_scaled] ,axis=1)
X_train_proc.shape
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(7000, 73)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># apply transformations on test set
num_scaled = scaler.transform(X_test[num_cols])

# encode categories
cat_encoded = encoder.transform(X_test[cat_cols])

# all together
X_test_proc = np.concatenate([cat_encoded, num_scaled] ,axis=1)
X_test_proc.shape
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(3000, 73)
</pre></div></div>
</div>
</div>
<div class="section" id="Hyper-parameter-tuning-and-Cross-Validation">
<h2>Hyper-parameter tuning and Cross Validation<a class="headerlink" href="#Hyper-parameter-tuning-and-Cross-Validation" title="Permalink to this headline">¶</a></h2>
<p>It is important to note that we are going to use the gridsearchCV method, so we can iterate over a series of hyper-parameters for each model in order to find the best combination of them through cross validation.</p>
</div>
<div class="section" id="Linear-regression-model">
<h2>Linear regression model<a class="headerlink" href="#Linear-regression-model" title="Permalink to this headline">¶</a></h2>
<p>Lets start trying a simple sklearn linear regression model, without regularization.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>%load_ext autoreload
%autoreload 2

import aux_functions as aux
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.linear_model import LinearRegression

model = LinearRegression()
grid_params = {&#39;fit_intercept&#39;: [True, False]}
name = &#39;Linear Regression&#39;
data = (X_train_proc, y_train, X_test_proc, y_test)

linear_results = aux.make_regressor(name, model, grid_params, data)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Linear Regression
Score r2: 0.9707
Score MSE: 2.122e+06
Time: 1.5e+01s
{&#39;copy_X&#39;: True, &#39;fit_intercept&#39;: False, &#39;n_jobs&#39;: None, &#39;normalize&#39;: False}
</pre></div></div>
</div>
</div>
<div class="section" id="Regularized-models---Ridge-regularization">
<h2>Regularized models - Ridge regularization<a class="headerlink" href="#Regularized-models---Ridge-regularization" title="Permalink to this headline">¶</a></h2>
<p>Ridge regression uses a penalty L2 factor for the least important regressors.</p>
<ul class="simple">
<li><p>L2: least squared deviation <span class="math notranslate nohighlight">\(resid = \sum{(y_i - \hat y_i)^2} + \lambda \sum{\beta^2}\)</span></p></li>
</ul>
<p>However, the least squares regularization is not robust: it is sensitive to outliers.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.linear_model import Ridge

model = Ridge()
grid_params = {&#39;alpha&#39;: [.001, .01, .1, 1]}
name = &#39;Ridge Regression&#39;
ridge_results = aux.make_regressor(name, model, grid_params, data)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ridge Regression
Score r2: 0.9707
Score MSE: 2.123e+06
Time: 4.1s
{&#39;alpha&#39;: 0.01, &#39;copy_X&#39;: True, &#39;fit_intercept&#39;: True, &#39;max_iter&#39;: None, &#39;normalize&#39;: False, &#39;random_state&#39;: None, &#39;solver&#39;: &#39;auto&#39;, &#39;tol&#39;: 0.001}
</pre></div></div>
</div>
</div>
<div class="section" id="Regularized-models---Lasso">
<h2>Regularized models - Lasso<a class="headerlink" href="#Regularized-models---Lasso" title="Permalink to this headline">¶</a></h2>
<p>Lasso regression uses a stronger penalty for the least important regressors, the L1.</p>
<p>That said, lasso will perform feature selection and it is not a stable solution.</p>
<ul class="simple">
<li><p>L1: least absolute deviation: <span class="math notranslate nohighlight">\(resid = \sum{(y_i - \hat y_i)^2} + \lambda \sum{|\beta|}\)</span></p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.linear_model import Lasso

model = Lasso()
grid_params = {&#39;alpha&#39;: [.001, .01, .1, 1]}
name = &#39;Lasso Regression&#39;
lasso_results = aux.make_regressor(name, model, grid_params, data)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Lasso Regression
Score r2: 0.9599
Score MSE: 2.637e+06
Time: 0.49s
{&#39;alpha&#39;: 0.001, &#39;copy_X&#39;: True, &#39;fit_intercept&#39;: True, &#39;max_iter&#39;: 1000, &#39;normalize&#39;: False, &#39;positive&#39;: False, &#39;precompute&#39;: False, &#39;random_state&#39;: None, &#39;selection&#39;: &#39;cyclic&#39;, &#39;tol&#39;: 0.0001, &#39;warm_start&#39;: False}
</pre></div></div>
</div>
</div>
<div class="section" id="Huber-Regressor">
<h2>Huber Regressor<a class="headerlink" href="#Huber-Regressor" title="Permalink to this headline">¶</a></h2>
<p>Huber uses L2 and L1 penalty. This makes it specially strong against outliers:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.linear_model import HuberRegressor

model = HuberRegressor(max_iter=1000)
grid_params = {
    &#39;alpha&#39;: [.001, .01, .1],
    &#39;epsilon&#39;: [1, 5, 10]
}
name = &#39;HUbber Regression&#39;
hubber_results = aux.make_regressor(name, model, grid_params, data)

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
HUbber Regression
Score r2: 0.9707
Score MSE: 2.123e+06
Time: 6.4e+01s
{&#39;alpha&#39;: 0.001, &#39;epsilon&#39;: 10, &#39;fit_intercept&#39;: True, &#39;max_iter&#39;: 1000, &#39;tol&#39;: 1e-05, &#39;warm_start&#39;: False}
</pre></div></div>
</div>
</div>
<div class="section" id="Comparing-models---MSE-and-R^2">
<h2>Comparing models - MSE and <span class="math notranslate nohighlight">\(R^2\)</span><a class="headerlink" href="#Comparing-models---MSE-and-R^2" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_scores = pd.DataFrame({
    &#39;MSE&#39;: [
        linear_results[2][&#39;mse&#39;],
        ridge_results[2][&#39;mse&#39;],
        lasso_results[2][&#39;mse&#39;],
        hubber_results[2][&#39;mse&#39;],

        ],
    &#39;r2&#39;: [
        linear_results[2][&#39;r2&#39;],
        ridge_results[2][&#39;r2&#39;],
        lasso_results[2][&#39;r2&#39;],
        hubber_results[2][&#39;r2&#39;],
        ],
    &#39;model name&#39;: [
        linear_results[2][&#39;model name&#39;],
        ridge_results[2][&#39;model name&#39;],
        lasso_results[2][&#39;model name&#39;],
        hubber_results[2][&#39;model name&#39;],
        ],
    &#39;time&#39;: [
        linear_results[2][&#39;time&#39;],
        ridge_results[2][&#39;time&#39;],
        lasso_results[2][&#39;time&#39;],
        hubber_results[2][&#39;time&#39;],
        ],
    },
#     index=[&#39;linear&#39;, &#39;ridge&#39;, &#39;lasso&#39;, &#39;hubber&#39;]
)

# load ols results
df_scores_ols = pd.read_csv(&#39;data/scores.csv&#39;)
df_scores = pd.concat([df_scores, df_scores_ols], axis=0)
df_scores.to_csv(&#39;data/sk_scores.csv&#39;, index=False)
df_scores.sort_values(by=&#39;MSE&#39;).round(4)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MSE</th>
      <th>r2</th>
      <th>model name</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.122211e+06</td>
      <td>0.9707</td>
      <td>Linear Regression</td>
      <td>14.9926</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2.123061e+06</td>
      <td>0.9707</td>
      <td>HUbber Regression</td>
      <td>63.8937</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.123265e+06</td>
      <td>0.9707</td>
      <td>Ridge Regression</td>
      <td>4.0631</td>
    </tr>
    <tr>
      <th>0</th>
      <td>2.175057e+06</td>
      <td>0.9690</td>
      <td>ols</td>
      <td>0.7920</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2.636549e+06</td>
      <td>0.9599</td>
      <td>Lasso Regression</td>
      <td>0.4869</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="Most-important-features">
<h2>Most important features<a class="headerlink" href="#Most-important-features" title="Permalink to this headline">¶</a></h2>
<p>Lets check what are the most important features, aside from make:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model = ridge_results[0]

cat_list = []
# make is the categories_[0]
for item in encoder.categories_[1:]:
    for cat in item:
        cat_list.append(cat)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>features = cat_list + num_cols
coefs = model.coef_

# coefs 0 to 21 are the make coefs
df_features = pd.DataFrame({&#39;feature&#39;: features, &#39;importance&#39;: coefs[21:]})
(df_features.sort_values(by=&#39;importance&#39;, ascending=False)
    .set_index(&#39;feature&#39;).head(10)
    .plot(kind=&#39;bar&#39;, figsize=(13, 5), rot=0)
)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.axes._subplots.AxesSubplot at 0x2340bb71a88&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/04-sklearn-linear_19_1.png" src="_images/04-sklearn-linear_19_1.png" />
</div>
</div>
</div>
<div class="section" id="Comparing-the-models---conclusions">
<h2>Comparing the models - conclusions<a class="headerlink" href="#Comparing-the-models---conclusions" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>MSE analysis shows better results for the Linear model: smallest MSE</p></li>
<li><p><span class="math notranslate nohighlight">\(R^2\)</span> analysis shows a tie between Ridge and Linear models</p></li>
<li><p>Ridge model would be the safest choice:</p></li>
<li><p>OLS has a worse performance because it was built on the assumption of a linear phenomena, using only linearly correlated variables.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_scores.sort_values(by=&#39;MSE&#39;).round(4)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MSE</th>
      <th>r2</th>
      <th>model name</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.122211e+06</td>
      <td>0.9707</td>
      <td>Linear Regression</td>
      <td>14.9926</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2.123061e+06</td>
      <td>0.9707</td>
      <td>HUbber Regression</td>
      <td>63.8937</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.123265e+06</td>
      <td>0.9707</td>
      <td>Ridge Regression</td>
      <td>4.0631</td>
    </tr>
    <tr>
      <th>0</th>
      <td>2.175057e+06</td>
      <td>0.9690</td>
      <td>ols</td>
      <td>0.7920</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2.636549e+06</td>
      <td>0.9599</td>
      <td>Lasso Regression</td>
      <td>0.4869</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
</div>


          </div>
          <div class="page-nav">
            <div class="inner"><ul class="page-nav">
  <li class="prev">
    <a href="03-ols.html"
       title="previous chapter">← Linear regression - OLS Model</a>
  </li>
  <li class="next">
    <a href="05-machine.html"
       title="next chapter">Modeling with machine learning →</a>
  </li>
</ul><div class="footer" role="contentinfo">
      &#169; Copyright 2020, Erick Medeiros Anastácio.
    <br>
    Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.1.1 with <a href="https://github.com/schettino72/sphinx_press_theme">Press Theme</a>.
</div>
            </div>
          </div>
      </page>
    </div>
    
    
  </body>
</html>