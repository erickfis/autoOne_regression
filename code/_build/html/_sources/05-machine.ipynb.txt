{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with machine learning\n",
    "\n",
    "In this section, we will cover:\n",
    "\n",
    "- fitting different machine learting regression models with sklearn\n",
    "- score analysis: MSE and variance explained: $R^2$\n",
    "- comparing the models: conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num_of_doors</th>\n",
       "      <th>body_style</th>\n",
       "      <th>drive_wheels</th>\n",
       "      <th>engine_location</th>\n",
       "      <th>wheel_base</th>\n",
       "      <th>length</th>\n",
       "      <th>...</th>\n",
       "      <th>engine_size</th>\n",
       "      <th>fuel_system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak_rpm</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>nissan</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>97.2</td>\n",
       "      <td>173.4</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>2bbl</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.47</td>\n",
       "      <td>8.5</td>\n",
       "      <td>97.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>9549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>165.7</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>9980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bmw</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>103.5</td>\n",
       "      <td>189.0</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>24565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>subaru</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>93.7</td>\n",
       "      <td>156.9</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>2bbl</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.36</td>\n",
       "      <td>9.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>5118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>mazda</td>\n",
       "      <td>diesel</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>104.9</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>idi</td>\n",
       "      <td>3.43</td>\n",
       "      <td>3.64</td>\n",
       "      <td>22.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>18344.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling        make fuel_type aspiration num_of_doors body_style  \\\n",
       "0          0      nissan       gas        std         four      sedan   \n",
       "1          3  volkswagen       gas        std          two  hatchback   \n",
       "2          1         bmw       gas        std         four      sedan   \n",
       "3          2      subaru       gas        std          two  hatchback   \n",
       "4          0       mazda    diesel        std         four      sedan   \n",
       "\n",
       "  drive_wheels engine_location  wheel_base  length  ...  engine_size  \\\n",
       "0          fwd           front        97.2   173.4  ...          120   \n",
       "1          fwd           front        94.5   165.7  ...          109   \n",
       "2          rwd           front       103.5   189.0  ...          164   \n",
       "3          fwd           front        93.7   156.9  ...           97   \n",
       "4          rwd           front       104.9   175.0  ...          134   \n",
       "\n",
       "   fuel_system  bore stroke compression_ratio  horsepower peak_rpm  city_mpg  \\\n",
       "0         2bbl  3.33   3.47               8.5        97.0   5200.0        27   \n",
       "1         mpfi  3.19   3.40               8.5        90.0   5500.0        24   \n",
       "2         mpfi  3.31   3.19               9.0       121.0   4250.0        20   \n",
       "3         2bbl  3.62   2.36               9.0        69.0   4900.0        31   \n",
       "4          idi  3.43   3.64              22.0        72.0   4200.0        31   \n",
       "\n",
       "   highway_mpg    price  \n",
       "0           34   9549.0  \n",
       "1           29   9980.0  \n",
       "2           25  24565.0  \n",
       "3           36   5118.0  \n",
       "4           39  18344.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/df_resample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "X.drop('price', axis=1, inplace=True)\n",
    "y = np.log(df.price) # as discussed, we are going to use the log transform here\n",
    "\n",
    "## Train-test split#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.3, random_state=95276\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize and encode\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import pickle\n",
    "\n",
    "with open('data/category_list', 'rb') as file:\n",
    "    cat_cols = pickle.load(file)\n",
    "\n",
    "# numeric columns\n",
    "num_cols = [col for col in X_train.columns if col not in cat_cols]\n",
    "\n",
    "# normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "num_scaled = scaler.fit_transform(X_train[num_cols])\n",
    "\n",
    "# encode categories\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "cat_encoded = encoder.fit_transform(X_train[cat_cols])\n",
    "\n",
    "# all together\n",
    "X_train_proc = np.concatenate([cat_encoded, num_scaled] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 73)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply transformations on test set\n",
    "num_scaled = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# encode categories\n",
    "cat_encoded = encoder.transform(X_test[cat_cols])\n",
    "\n",
    "# all together\n",
    "X_test_proc = np.concatenate([cat_encoded, num_scaled] ,axis=1)\n",
    "X_test_proc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning and Cross Validation\n",
    "\n",
    "It is important to note that we are going to use the gridsearchCV method, so we can iterate over a series of hyper-parameters for each model in order to find the best combination of them through cross validation.\n",
    "\n",
    "## Decision Tree Regressor\n",
    "\n",
    "\n",
    "Lets start trying a simple sklearn decision tree regression model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import aux_functions as aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree\n",
      "Score r2: 0.9985 \n",
      "Score MSE: 7.789e+04 \n",
      "Time: 1.2e+01s\n",
      "{'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 20, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 95276, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=95276)\n",
    "\n",
    "grid_params = {\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "    'max_depth': [20, 25, 30]\n",
    "}\n",
    "name = 'Decision tree'\n",
    "data = (X_train_proc, y_train, X_test_proc, y_test)\n",
    "\n",
    "dt_results = aux.make_regressor(name, model, grid_params, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n",
      "Score r2: 0.9985 \n",
      "Score MSE: 8.469e+04 \n",
      "Time: 1.3s\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "grid_params = {\n",
    "    'n_neighbors': [5, 10],\n",
    "    'p': [1, 2]\n",
    "    }\n",
    "name = 'knn'\n",
    "knn_results = aux.make_regressor(name, model, grid_params, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "Score r2: 0.9985 \n",
      "Score MSE: 7.796e+04 \n",
      "Time: 1.4e+01s\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 30, 'max_features': 10, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "grid_params = {\n",
    "    'max_features': [10, 15, 20],\n",
    "    'max_depth': [20, 30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "}\n",
    "name = 'RF'\n",
    "rf_results = aux.make_regressor(name, model, grid_params, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient tree boosting\n",
    "\n",
    "\n",
    "The gradient tree boosting is an ensemble machine learning methods too, but this time we have the boosting class: several weak models are combined to produce a powerful estimator with reduced bias.\n",
    "\n",
    "This method is very robust because it uses regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost\n",
      "Score r2: 0.9883 \n",
      "Score MSE: 5.876e+05 \n",
      "Time: 4.7s\n",
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "grid_params = {\n",
    "    'min_samples_split': [5],\n",
    "}\n",
    "name = 'Gradient Boost'\n",
    "gb_results = aux.make_regressor(name, model, grid_params, data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "Adaboost is another ensemble machine learning method of the boosting class.\n",
    "\n",
    "This time, however, we can start with the best model we have so far. Then, copies of the original model will be fitted on the same dataset, but weights will be attributed to them according to the error of the prediction.\n",
    "\n",
    "Lets use our previously trained decision tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "Score r2: 0.9985 \n",
      "Score MSE: 7.865e+04 \n",
      "Time: 1.1s\n",
      "{'base_estimator__ccp_alpha': 0.0, 'base_estimator__criterion': 'mse', 'base_estimator__max_depth': 20, 'base_estimator__max_features': None, 'base_estimator__max_leaf_nodes': None, 'base_estimator__min_impurity_decrease': 0.0, 'base_estimator__min_impurity_split': None, 'base_estimator__min_samples_leaf': 2, 'base_estimator__min_samples_split': 2, 'base_estimator__min_weight_fraction_leaf': 0.0, 'base_estimator__presort': 'deprecated', 'base_estimator__random_state': 95276, 'base_estimator__splitter': 'best', 'base_estimator': DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=20,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=95276, splitter='best'), 'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 50, 'random_state': 95276}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor(random_state=95276, base_estimator=dt_results[0])\n",
    "\n",
    "grid_params = {\n",
    "    'learning_rate': [.5, 1],\n",
    "}\n",
    "name = 'AdaBoost'\n",
    "ada_results = aux.make_regressor(name, model, grid_params, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models - MSE and $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>r2</th>\n",
       "      <th>time</th>\n",
       "      <th>rmse</th>\n",
       "      <th>dif_rmse</th>\n",
       "      <th>dif_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lasso Regression</th>\n",
       "      <td>2.636549e+06</td>\n",
       "      <td>0.959884</td>\n",
       "      <td>0.486873</td>\n",
       "      <td>1623.745228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ols</th>\n",
       "      <td>2.175057e+06</td>\n",
       "      <td>0.968982</td>\n",
       "      <td>0.791958</td>\n",
       "      <td>1474.807567</td>\n",
       "      <td>-148.937661</td>\n",
       "      <td>0.305085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>2.123265e+06</td>\n",
       "      <td>0.970746</td>\n",
       "      <td>4.063064</td>\n",
       "      <td>1457.142861</td>\n",
       "      <td>-17.664706</td>\n",
       "      <td>3.271106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUbber Regression</th>\n",
       "      <td>2.123061e+06</td>\n",
       "      <td>0.970747</td>\n",
       "      <td>63.893663</td>\n",
       "      <td>1457.072903</td>\n",
       "      <td>-0.069958</td>\n",
       "      <td>59.830599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>2.122211e+06</td>\n",
       "      <td>0.970749</td>\n",
       "      <td>14.992601</td>\n",
       "      <td>1456.781135</td>\n",
       "      <td>-0.291768</td>\n",
       "      <td>-48.901062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>5.875705e+05</td>\n",
       "      <td>0.988288</td>\n",
       "      <td>4.675656</td>\n",
       "      <td>766.531489</td>\n",
       "      <td>-690.249646</td>\n",
       "      <td>-10.316944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>8.468664e+04</td>\n",
       "      <td>0.998462</td>\n",
       "      <td>1.290188</td>\n",
       "      <td>291.009689</td>\n",
       "      <td>-475.521800</td>\n",
       "      <td>-3.385468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>7.864713e+04</td>\n",
       "      <td>0.998501</td>\n",
       "      <td>1.094820</td>\n",
       "      <td>280.440957</td>\n",
       "      <td>-10.568732</td>\n",
       "      <td>-0.195367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>7.795997e+04</td>\n",
       "      <td>0.998517</td>\n",
       "      <td>13.942496</td>\n",
       "      <td>279.213125</td>\n",
       "      <td>-1.227832</td>\n",
       "      <td>12.847676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>7.788908e+04</td>\n",
       "      <td>0.998518</td>\n",
       "      <td>12.456983</td>\n",
       "      <td>279.086156</td>\n",
       "      <td>-0.126970</td>\n",
       "      <td>-1.485513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MSE        r2       time         rmse    dif_rmse  \\\n",
       "model name                                                                      \n",
       "Lasso Regression   2.636549e+06  0.959884   0.486873  1623.745228         NaN   \n",
       "ols                2.175057e+06  0.968982   0.791958  1474.807567 -148.937661   \n",
       "Ridge Regression   2.123265e+06  0.970746   4.063064  1457.142861  -17.664706   \n",
       "HUbber Regression  2.123061e+06  0.970747  63.893663  1457.072903   -0.069958   \n",
       "Linear Regression  2.122211e+06  0.970749  14.992601  1456.781135   -0.291768   \n",
       "Gradient Boost     5.875705e+05  0.988288   4.675656   766.531489 -690.249646   \n",
       "knn                8.468664e+04  0.998462   1.290188   291.009689 -475.521800   \n",
       "AdaBoost           7.864713e+04  0.998501   1.094820   280.440957  -10.568732   \n",
       "RF                 7.795997e+04  0.998517  13.942496   279.213125   -1.227832   \n",
       "Decision tree      7.788908e+04  0.998518  12.456983   279.086156   -0.126970   \n",
       "\n",
       "                    dif_time  \n",
       "model name                    \n",
       "Lasso Regression         NaN  \n",
       "ols                 0.305085  \n",
       "Ridge Regression    3.271106  \n",
       "HUbber Regression  59.830599  \n",
       "Linear Regression -48.901062  \n",
       "Gradient Boost    -10.316944  \n",
       "knn                -3.385468  \n",
       "AdaBoost           -0.195367  \n",
       "RF                 12.847676  \n",
       "Decision tree      -1.485513  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.DataFrame({\n",
    "    'MSE': [\n",
    "        dt_results[2]['mse'],\n",
    "        knn_results[2]['mse'],\n",
    "        rf_results[2]['mse'],\n",
    "        gb_results[2]['mse'],\n",
    "        ada_results[2]['mse']\n",
    "\n",
    "        ],\n",
    "    'r2': [\n",
    "        dt_results[2]['r2'],\n",
    "        knn_results[2]['r2'],\n",
    "        rf_results[2]['r2'],\n",
    "        gb_results[2]['r2'],\n",
    "        ada_results[2]['r2']\n",
    "        ],\n",
    "    'model name': [\n",
    "        dt_results[2]['model name'],\n",
    "        knn_results[2]['model name'],\n",
    "        rf_results[2]['model name'],\n",
    "        gb_results[2]['model name'],\n",
    "        ada_results[2]['model name']\n",
    "        ],\n",
    "    'time': [\n",
    "        dt_results[2]['time'],\n",
    "        knn_results[2]['time'],\n",
    "        rf_results[2]['time'],\n",
    "        gb_results[2]['time'],\n",
    "        ada_results[2]['time'],\n",
    "        ],\n",
    "    },\n",
    "#     index=['linear', 'ridge', 'lasso', 'hubber']\n",
    ")\n",
    "\n",
    "# load ols results\n",
    "df_scores_old = pd.read_csv('data/sk_scores.csv')\n",
    "df_scores = pd.concat([df_scores, df_scores_old], axis=0)\n",
    "\n",
    "# lets get the rmse\n",
    "df_scores['rmse'] = np.sqrt(df_scores['MSE'])\n",
    "\n",
    "# now lets measure the impact of processing time over RMSE\n",
    "df_scores = df_scores.sort_values(by='rmse', ascending=False)\n",
    "df_scores['dif_rmse'] = df_scores['rmse'].diff()\n",
    "df_scores['dif_time'] = df_scores['time'].diff()\n",
    "df_scores.to_csv('data/full_scores.csv', index=False)\n",
    "df_scores.set_index('model name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Considering the computation time and the error measured on the test set, we can conclude that:\n",
    "\n",
    "- OLS is not a good choice here unless we add the non-linear contributions of each feature to the explain the outcome.\n",
    "- Given that all sklearn linear models have almost the same scores, Ridge Regression would be chosen due to the time it needs to be trained while automatically adjusting the weights of each feature, so we don't need to manually select them\n",
    "- among the ML models, its important to note that the KNN model took 10x less time to produce a model almost as good as the alternatives.\n",
    "- ML have 5x improved performance (RMSE) over Linear Models because it doesn't rely on the linear correlations between predictors and the outcome. The linear models could have better performance if we added the contributions of interdependent terms or non-linear transformations of them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
