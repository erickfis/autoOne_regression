{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with machine learning\n",
    "\n",
    "In this section, we will cover:\n",
    "\n",
    "- fitting different machine learting regression models with sklearn\n",
    "- score analysis: MSE and variance explained: $R^2$\n",
    "- comparing the models: conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num_of_doors</th>\n",
       "      <th>body_style</th>\n",
       "      <th>drive_wheels</th>\n",
       "      <th>engine_location</th>\n",
       "      <th>wheel_base</th>\n",
       "      <th>length</th>\n",
       "      <th>...</th>\n",
       "      <th>engine_size</th>\n",
       "      <th>fuel_system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression_ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak_rpm</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>mitsubishi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>93.7</td>\n",
       "      <td>157.3</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>2bbl</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.23</td>\n",
       "      <td>9.4</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>5389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dodge</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>93.7</td>\n",
       "      <td>157.3</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>2bbl</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.23</td>\n",
       "      <td>9.4</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>6692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>jaguar</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>102.0</td>\n",
       "      <td>191.7</td>\n",
       "      <td>...</td>\n",
       "      <td>326</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.76</td>\n",
       "      <td>11.5</td>\n",
       "      <td>262.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>36000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>peugot</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>107.9</td>\n",
       "      <td>186.7</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.19</td>\n",
       "      <td>8.4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>11900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>subaru</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>97.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.64</td>\n",
       "      <td>7.7</td>\n",
       "      <td>111.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>11259.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling        make fuel_type aspiration num_of_doors body_style  \\\n",
       "0          2  mitsubishi       gas        std          two  hatchback   \n",
       "1          1       dodge       gas        std         four      sedan   \n",
       "2          0      jaguar       gas        std          two      sedan   \n",
       "3          0      peugot       gas        std         four      sedan   \n",
       "4          0      subaru       gas      turbo         four      sedan   \n",
       "\n",
       "  drive_wheels engine_location  wheel_base  length  ...  engine_size  \\\n",
       "0          fwd           front        93.7   157.3  ...           92   \n",
       "1          fwd           front        93.7   157.3  ...           90   \n",
       "2          rwd           front       102.0   191.7  ...          326   \n",
       "3          rwd           front       107.9   186.7  ...          120   \n",
       "4          fwd           front        97.0   172.0  ...          108   \n",
       "\n",
       "   fuel_system  bore stroke compression_ratio  horsepower peak_rpm  city_mpg  \\\n",
       "0         2bbl  2.97   3.23               9.4        68.0   5500.0        37   \n",
       "1         2bbl  2.97   3.23               9.4        68.0   5500.0        31   \n",
       "2         mpfi  3.54   2.76              11.5       262.0   5000.0        13   \n",
       "3         mpfi  3.46   3.19               8.4        97.0   5000.0        19   \n",
       "4         mpfi  3.62   2.64               7.7       111.0   4800.0        24   \n",
       "\n",
       "   highway_mpg    price  \n",
       "0           41   5389.0  \n",
       "1           38   6692.0  \n",
       "2           17  36000.0  \n",
       "3           24  11900.0  \n",
       "4           29  11259.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/df_resample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "X.drop('price', axis=1, inplace=True)\n",
    "y = np.log(df.price) # as discussed, we are going to use the log transform here\n",
    "\n",
    "## Train-test split#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.3, random_state=95276\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize and encode\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import pickle\n",
    "\n",
    "with open('data/category_list', 'rb') as file:\n",
    "    cat_cols = pickle.load(file)\n",
    "\n",
    "# numeric columns\n",
    "num_cols = [col for col in X_train.columns if col not in cat_cols]\n",
    "\n",
    "# normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "num_scaled = scaler.fit_transform(X_train[num_cols])\n",
    "\n",
    "# encode categories\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "cat_encoded = encoder.fit_transform(X_train[cat_cols])\n",
    "\n",
    "# all together\n",
    "X_train_proc = np.concatenate([cat_encoded, num_scaled] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 73)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply transformations on test set\n",
    "num_scaled = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# encode categories\n",
    "cat_encoded = encoder.transform(X_test[cat_cols])\n",
    "\n",
    "# all together\n",
    "X_test_proc = np.concatenate([cat_encoded, num_scaled] ,axis=1)\n",
    "X_test_proc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning and Cross Validation\n",
    "\n",
    "It is important to note that we are going to use the gridsearchCV method, so we can iterate over a series of hyper-parameters for each model in order to find the best combination of them through cross validation.\n",
    "\n",
    "## Decision Tree Regressor\n",
    "\n",
    "\n",
    "Lets start trying a simple sklearn decision tree regression model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import aux_functions as aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree\n",
      "Score r2: 0.9986 \n",
      "Score MSE: 7.89e+04 \n",
      "Time: 1.8e+01s\n",
      "{'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 20, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 95276, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=95276)\n",
    "\n",
    "grid_params = {\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "    'max_depth': [20, 25, 30]\n",
    "}\n",
    "name = 'Decision tree'\n",
    "data = (X_train_proc, y_train, X_test_proc, y_test)\n",
    "\n",
    "dt_results = aux.make_regressor(name, model, grid_params, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n",
      "Score r2: 0.9984 \n",
      "Score MSE: 1.006e+05 \n",
      "Time: 2.2s\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 10, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "grid_params = {\n",
    "    'n_neighbors': [5, 10],\n",
    "    'p': [1, 2]\n",
    "    }\n",
    "name = 'knn'\n",
    "knn_results = aux.make_regressor(name, model, grid_params, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "Score r2: 0.9986 \n",
      "Score MSE: 7.915e+04 \n",
      "Time: 2.3e+01s\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 30, 'max_features': 20, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "grid_params = {\n",
    "    'max_features': [10, 15, 20],\n",
    "    'max_depth': [20, 30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "}\n",
    "name = 'RF'\n",
    "rf_results = aux.make_regressor(name, model, grid_params, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient tree boosting\n",
    "\n",
    "\n",
    "The gradient tree boosting is an ensemble machine learning methods too, but this time we have the boosting class: several weak models are combined to produce a powerful estimator with reduced bias.\n",
    "\n",
    "This method is very robust because it uses regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost\n",
      "Score r2: 0.9871 \n",
      "Score MSE: 5.658e+05 \n",
      "Time: 8.0s\n",
      "{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'presort': 'deprecated', 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "grid_params = {\n",
    "    'min_samples_split': [5],\n",
    "}\n",
    "name = 'Gradient Boost'\n",
    "gb_results = aux.make_regressor(name, model, grid_params, data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "Adaboost is another ensemble machine learning method of the boosting class.\n",
    "\n",
    "This time, however, we can start with the best model we have so far. Then, copies of the original model will be fitted on the same dataset, but weights will be attributed to them according to the error of the prediction.\n",
    "\n",
    "Lets use our previously trained decision tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "Score r2: 0.9986 \n",
      "Score MSE: 7.917e+04 \n",
      "Time: 2.4s\n",
      "{'base_estimator__ccp_alpha': 0.0, 'base_estimator__criterion': 'mse', 'base_estimator__max_depth': 20, 'base_estimator__max_features': None, 'base_estimator__max_leaf_nodes': None, 'base_estimator__min_impurity_decrease': 0.0, 'base_estimator__min_impurity_split': None, 'base_estimator__min_samples_leaf': 2, 'base_estimator__min_samples_split': 2, 'base_estimator__min_weight_fraction_leaf': 0.0, 'base_estimator__presort': 'deprecated', 'base_estimator__random_state': 95276, 'base_estimator__splitter': 'best', 'base_estimator': DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=20,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=95276, splitter='best'), 'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 50, 'random_state': 95276}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor(random_state=95276, base_estimator=dt_results[0])\n",
    "\n",
    "grid_params = {\n",
    "    'learning_rate': [.5, 1],\n",
    "}\n",
    "name = 'AdaBoost'\n",
    "ada_results = aux.make_regressor(name, model, grid_params, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models - MSE and $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>r2</th>\n",
       "      <th>model name</th>\n",
       "      <th>time</th>\n",
       "      <th>rmse</th>\n",
       "      <th>dif_rmse</th>\n",
       "      <th>dif_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.618442e+06</td>\n",
       "      <td>0.962031</td>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>0.474396</td>\n",
       "      <td>1272.179898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.211086e+06</td>\n",
       "      <td>0.968962</td>\n",
       "      <td>ols</td>\n",
       "      <td>0.701995</td>\n",
       "      <td>1100.493742</td>\n",
       "      <td>-171.686156</td>\n",
       "      <td>0.227598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.157179e+06</td>\n",
       "      <td>0.971413</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>3.785377</td>\n",
       "      <td>1075.722459</td>\n",
       "      <td>-24.771283</td>\n",
       "      <td>3.083382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.156863e+06</td>\n",
       "      <td>0.971421</td>\n",
       "      <td>HUbber Regression</td>\n",
       "      <td>69.701672</td>\n",
       "      <td>1075.575433</td>\n",
       "      <td>-0.147026</td>\n",
       "      <td>65.916295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.156840e+06</td>\n",
       "      <td>0.971422</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>13.188963</td>\n",
       "      <td>1075.565067</td>\n",
       "      <td>-0.010367</td>\n",
       "      <td>-56.512709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.657781e+05</td>\n",
       "      <td>0.987106</td>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>7.981411</td>\n",
       "      <td>752.182200</td>\n",
       "      <td>-323.382866</td>\n",
       "      <td>-5.207552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.005970e+05</td>\n",
       "      <td>0.998437</td>\n",
       "      <td>knn</td>\n",
       "      <td>2.226510</td>\n",
       "      <td>317.170259</td>\n",
       "      <td>-435.011942</td>\n",
       "      <td>-5.754901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.916639e+04</td>\n",
       "      <td>0.998595</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>2.420043</td>\n",
       "      <td>281.365229</td>\n",
       "      <td>-35.805029</td>\n",
       "      <td>0.193533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.915360e+04</td>\n",
       "      <td>0.998599</td>\n",
       "      <td>RF</td>\n",
       "      <td>23.239215</td>\n",
       "      <td>281.342490</td>\n",
       "      <td>-0.022739</td>\n",
       "      <td>20.819172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.890253e+04</td>\n",
       "      <td>0.998604</td>\n",
       "      <td>Decision tree</td>\n",
       "      <td>17.802543</td>\n",
       "      <td>280.895950</td>\n",
       "      <td>-0.446540</td>\n",
       "      <td>-5.436672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSE        r2         model name       time         rmse  \\\n",
       "2  1.618442e+06  0.962031   Lasso Regression   0.474396  1272.179898   \n",
       "4  1.211086e+06  0.968962                ols   0.701995  1100.493742   \n",
       "1  1.157179e+06  0.971413   Ridge Regression   3.785377  1075.722459   \n",
       "3  1.156863e+06  0.971421  HUbber Regression  69.701672  1075.575433   \n",
       "0  1.156840e+06  0.971422  Linear Regression  13.188963  1075.565067   \n",
       "3  5.657781e+05  0.987106     Gradient Boost   7.981411   752.182200   \n",
       "1  1.005970e+05  0.998437                knn   2.226510   317.170259   \n",
       "4  7.916639e+04  0.998595           AdaBoost   2.420043   281.365229   \n",
       "2  7.915360e+04  0.998599                 RF  23.239215   281.342490   \n",
       "0  7.890253e+04  0.998604      Decision tree  17.802543   280.895950   \n",
       "\n",
       "     dif_rmse   dif_time  \n",
       "2         NaN        NaN  \n",
       "4 -171.686156   0.227598  \n",
       "1  -24.771283   3.083382  \n",
       "3   -0.147026  65.916295  \n",
       "0   -0.010367 -56.512709  \n",
       "3 -323.382866  -5.207552  \n",
       "1 -435.011942  -5.754901  \n",
       "4  -35.805029   0.193533  \n",
       "2   -0.022739  20.819172  \n",
       "0   -0.446540  -5.436672  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.DataFrame({\n",
    "    'MSE': [\n",
    "        dt_results[2]['mse'],\n",
    "        knn_results[2]['mse'],\n",
    "        rf_results[2]['mse'],\n",
    "        gb_results[2]['mse'],\n",
    "        ada_results[2]['mse']\n",
    "\n",
    "        ],\n",
    "    'r2': [\n",
    "        dt_results[2]['r2'],\n",
    "        knn_results[2]['r2'],\n",
    "        rf_results[2]['r2'],\n",
    "        gb_results[2]['r2'],\n",
    "        ada_results[2]['r2']\n",
    "        ],\n",
    "    'model name': [\n",
    "        dt_results[2]['model name'],\n",
    "        knn_results[2]['model name'],\n",
    "        rf_results[2]['model name'],\n",
    "        gb_results[2]['model name'],\n",
    "        ada_results[2]['model name']\n",
    "        ],\n",
    "    'time': [\n",
    "        dt_results[2]['time'],\n",
    "        knn_results[2]['time'],\n",
    "        rf_results[2]['time'],\n",
    "        gb_results[2]['time'],\n",
    "        ada_results[2]['time'],\n",
    "        ],\n",
    "    },\n",
    "#     index=['linear', 'ridge', 'lasso', 'hubber']\n",
    ")\n",
    "\n",
    "# load ols results\n",
    "df_scores_old = pd.read_csv('data/sk_scores.csv')\n",
    "df_scores = pd.concat([df_scores, df_scores_old], axis=0)\n",
    "\n",
    "# lets get the rmse\n",
    "df_scores['rmse'] = np.sqrt(df_scores['MSE'])\n",
    "\n",
    "# now lets measure the impact of processing time over RMSE\n",
    "df_scores = df_scores.sort_values(by='rmse', ascending=False)\n",
    "df_scores['dif_rmse'] = df_scores['rmse'].diff()\n",
    "df_scores['dif_time'] = df_scores['time'].diff()\n",
    "df_scores.to_csv('data/full_scores.csv', index=False)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Considering the computation time and the error measured on the test set, we can conclude that:\n",
    "\n",
    "- OLS, with proper feature selection, would be chosen over sklearn. However, its important to consider the time it takes to manually choose those features\n",
    "- Given that all sklearn linear models have almost the same scores, Ridge Regression would be chosen due to the time it needs to be trained while automatically adjusting the weights of each feature, so we don't need to manually select them\n",
    "- among the ML models, its important to note that the KNN model took 6x less time to produce a model almost as good as the alternatives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
