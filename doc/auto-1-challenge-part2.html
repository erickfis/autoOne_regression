
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Auto-1 Data Science Challenge &#8212; AutoOne Regression 1.0 documentation</title>
    <link rel="stylesheet" href="_static/pyramid.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Neuton&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Nobile:regular,italic,bold,bolditalic&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

  </head><body>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">AutoOne Regression 1.0 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Auto-1 Data Science Challenge</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Auto-1-Data-Science-Challenge">
<h1>Auto-1 Data Science Challenge<a class="headerlink" href="#Auto-1-Data-Science-Challenge" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="Part-2---Modeling">
<h1>Part 2 - Modeling<a class="headerlink" href="#Part-2---Modeling" title="Permalink to this headline">¶</a></h1>
<p>In this section, we will cover:</p>
<ul class="simple">
<li><p>analysis of sample distribution</p></li>
<li><p>fitting different linear repression models</p></li>
<li><p>analysis of variance explained: <span class="math notranslate nohighlight">\(R^2\)</span></p></li>
<li><p>analysis of MSE - mean squared error</p></li>
<li><p>residual analysis</p></li>
<li><p>analysis of fitted values distribution</p></li>
<li><p>most important features</p></li>
<li><p>comparing the models: conclusions</p></li>
<li><p>improving the model</p></li>
<li><p>using the model to predict NA prices</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># preparing the data

import pandas as pd
import numpy as np

df = pd.read_pickle(&#39;df_clean.pkl&#39;)
df.isnull().sum()[df.isnull().sum()&gt;0]
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
normalized_losses    38
price                 4
dtype: int64
</pre></div></div>
</div>
<div class="section" id="Analysis-of-sample-distribution">
<h2>Analysis of sample distribution<a class="headerlink" href="#Analysis-of-sample-distribution" title="Permalink to this headline">¶</a></h2>
<p>Before splitting train and test, let’s look out how balanced the data is:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>import matplotlib.pyplot as plt
%matplotlib inline
fig, (ax, ax2) = plt.subplots(ncols=2, sharey=False)

df.price.plot(kind=&#39;kde&#39;, legend=False, ax=ax,  figsize=(14,7))
df.price.plot(kind=&#39;hist&#39;,ax=ax2, figsize=(14,7))
plt.show()

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/auto-1-challenge-part2_4_0.png" src="_images/auto-1-challenge-part2_4_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df.price.plot(kind=&#39;box&#39;, legend=False, figsize=(5,5))
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.axes._subplots.AxesSubplot at 0x7efc2a129eb8&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/auto-1-challenge-part2_5_1.png" src="_images/auto-1-challenge-part2_5_1.png" />
</div>
</div>
<p>From the density plot, it looks like our data follows a <em>bimodal distribution</em>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df.price.describe()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
count      193.000000
mean     13285.025907
std       8089.082886
min       5118.000000
25%       7738.000000
50%      10245.000000
75%      16515.000000
max      45400.000000
Name: price, dtype: float64
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>top_wisker = df.price.quantile(.75) + 1.5*(df.price.quantile(.75) - df.price.quantile(.25))
top_wisker
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
29680.5
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># prob for y &gt; top_wisker
import scipy.stats as st
1- st.norm.cdf(top_wisker, df.price.mean(), df.price.std())
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.021338141309260816
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>st.norm.ppf(.99, df.price.mean(), df.price.std()) # just exploring
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
32103.046680808613
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>st.norm.cdf(32000, df.price.mean(), df.price.std()) # just exploring
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.98965540725691292
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>

<span></span>df[&quot;class_range&quot;] = pd.cut(df.price, 7,
                               labels=[&#39;almost_free&#39;, &#39;super-cheap&#39;, &#39;cheap&#39;, &#39;normal&#39;, &#39;expensive&#39;,
                                       &#39;super_expensive&#39;, &#39;rich_only&#39;])

df[[&#39;class_range&#39;, &#39;price&#39;]].sample(10)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>class_range</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>83</th>
      <td>super-cheap</td>
      <td>14869.0</td>
    </tr>
    <tr>
      <th>74</th>
      <td>rich_only</td>
      <td>45400.0</td>
    </tr>
    <tr>
      <th>44</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>173</th>
      <td>almost_free</td>
      <td>8948.0</td>
    </tr>
    <tr>
      <th>197</th>
      <td>super-cheap</td>
      <td>16515.0</td>
    </tr>
    <tr>
      <th>88</th>
      <td>almost_free</td>
      <td>9279.0</td>
    </tr>
    <tr>
      <th>107</th>
      <td>super-cheap</td>
      <td>11900.0</td>
    </tr>
    <tr>
      <th>192</th>
      <td>super-cheap</td>
      <td>13845.0</td>
    </tr>
    <tr>
      <th>81</th>
      <td>almost_free</td>
      <td>8499.0</td>
    </tr>
    <tr>
      <th>172</th>
      <td>cheap</td>
      <td>17669.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df.groupby(&#39;class_range&#39;)[[&#39;price&#39;]] .min() # starting prices for each class
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>price</th>
    </tr>
    <tr>
      <th>class_range</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>almost_free</th>
      <td>5118.0</td>
    </tr>
    <tr>
      <th>super-cheap</th>
      <td>10898.0</td>
    </tr>
    <tr>
      <th>cheap</th>
      <td>16630.0</td>
    </tr>
    <tr>
      <th>normal</th>
      <td>22470.0</td>
    </tr>
    <tr>
      <th>expensive</th>
      <td>28176.0</td>
    </tr>
    <tr>
      <th>super_expensive</th>
      <td>34028.0</td>
    </tr>
    <tr>
      <th>rich_only</th>
      <td>40960.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df.class_range.value_counts()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
almost_free        101
super-cheap         45
cheap               26
super_expensive      7
expensive            6
normal               5
rich_only            3
Name: class_range, dtype: int64
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df.class_range.value_counts(normalize=True).plot.bar()
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.axes._subplots.AxesSubplot at 0x7efc2a2cae48&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/auto-1-challenge-part2_15_1.png" src="_images/auto-1-challenge-part2_15_1.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df.price.value_counts?
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df.class_range.value_counts().plot.bar
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;bound method SeriesPlotMethods.bar of &lt;pandas.plotting._core.SeriesPlotMethods object at 0x7efc2a19b080&gt;&gt;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df.shape
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(197, 27)
</pre></div></div>
</div>
<p>From this brief analysis about prices, we found that: - the distribution is not normal - could be bimodal as well - there is no balance on price ranges, therefore we must take precautions when splitting the train/test sets</p>
<p>Besides, please notice that this <em>class_range</em> feature was created only to show how unbalanced the price ranges are on this dataset. We are not going to use this <em>class_range</em> feature on our model because this information won’t be present when predicting prices for new cars.</p>
<p>Then again, we could chose to predict this <em>class_range</em> for each car instead of it’s price. It’s an easier task.</p>
<div class="section" id="Discussion-about-outliers:">
<h3>Discussion about outliers:<a class="headerlink" href="#Discussion-about-outliers:" title="Permalink to this headline">¶</a></h3>
<p>There are data points which are outside of the expected range of the normal distribution of prices and therefore could be outliers.</p>
<p>This happens either because they really are outliers or because this is not a normal distribution.</p>
<p>We must test those data points because if they are real outliers, there is a change they could be influential points which are going to leverage the model.</p>
<p>Lets see about that later.</p>
</div>
</div>
<div class="section" id="Balancing-the-data:-bootstrap">
<h2>Balancing the data: bootstrap<a class="headerlink" href="#Balancing-the-data:-bootstrap" title="Permalink to this headline">¶</a></h2>
<p>Our dataset has only 197 records and some classes are not well represented here. We will fix this balance issue through bootstrap: lets make our data grown by random sampling it:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_old = df.copy()
df = df.sample(10000, replace=True)
df.shape
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(10000, 27)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>fig, (ax, ax2) = plt.subplots(ncols=2, sharey=False)

df_old.price.plot(kind=&#39;kde&#39;, legend=False, ax=ax,  figsize=(14,7))
df.price.plot(kind=&#39;kde&#39;,ax=ax2, figsize=(14,7))
plt.show()

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/auto-1-challenge-part2_22_0.png" src="_images/auto-1-challenge-part2_22_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>fig, (ax, ax2) = plt.subplots(ncols=2, sharey=False)
#(kind=&#39;kde&#39;, legend=False, ax=ax,  figsize=(14,7))
df_old.class_range.value_counts().plot.bar(ax=ax, figsize=(14,7))
df.class_range.value_counts().plot.bar(ax=ax2, figsize=(14,7))
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.axes._subplots.AxesSubplot at 0x7efc277d0b00&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/auto-1-challenge-part2_23_1.png" src="_images/auto-1-challenge-part2_23_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>print(df.class_range.value_counts(), df_old.class_range.value_counts())
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
almost_free        5007
super-cheap        2390
cheap              1302
super_expensive     361
expensive           338
normal              245
rich_only           152
Name: class_range, dtype: int64 almost_free        101
super-cheap         45
cheap               26
super_expensive      7
expensive            6
normal               5
rich_only            3
Name: class_range, dtype: int64
</pre></div></div>
</div>
</div>
<div class="section" id="Fitting-the-models">
<h2>Fitting the models<a class="headerlink" href="#Fitting-the-models" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>#Since there is a lot of missing data for *normalized_losses*,
# we chose to fit a model without this feature:

X = df.copy()
X.drop([&#39;normalized_losses&#39;, &#39;class_range&#39;], axis=1, inplace=True)
X.dropna(subset=[&#39;price&#39;], inplace=True)
y = X.price
X.drop(&#39;price&#39;, axis=1, inplace=True)

</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># now the split in a stratified way
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,
                                                    random_state=95276, stratify=y)

</pre></div>
</div>
</div>
<div class="section" id="OLS-with-feature-selection-through-analysis">
<h3>OLS with feature selection through analysis<a class="headerlink" href="#OLS-with-feature-selection-through-analysis" title="Permalink to this headline">¶</a></h3>
<p>This is the proper way of fitting a OLS model: carefully choosing which feature will be included into the model, because:</p>
<ul class="simple">
<li><p>including unnecessary features (that are correlated to the features already in the model) increases the standard error of the coefficients</p></li>
<li><p>excluding necessary features results in bias</p></li>
</ul>
<p>So, lets first look for correlation between features:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>num_feats = list(X_train.describe().columns)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>cat_feats = list(X_train.columns)
for feat in num_feats:
    cat_feats.remove(feat)
cat_feats
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;make&#39;,
 &#39;fuel_type&#39;,
 &#39;aspiration&#39;,
 &#39;num_of_doors&#39;,
 &#39;body_style&#39;,
 &#39;drive_wheels&#39;,
 &#39;engine_location&#39;,
 &#39;engine_type&#39;,
 &#39;num_of_cylinders&#39;,
 &#39;fuel_system&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>formula = &#39;&#39;
for feat in cat_feats:
    formula = formula + &#39; + C({0})&#39;.format(feat)
formula = formula[2::]
formula = &#39;price ~&#39; + formula
formula
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;price ~ C(make) + C(fuel_type) + C(aspiration) + C(num_of_doors) + C(body_style) + C(drive_wheels) + C(engine_location) + C(engine_type) + C(num_of_cylinders) + C(fuel_system)&#39;
</pre></div></div>
</div>
<p>Now lets add numeric features which are not correlated to each other:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_cor = X_train[num_feats].corr()
df_cor = df_cor[df_cor&gt;.8]
df_cor = df_cor[df_cor!=1]
df_cor.dropna(how=&#39;all&#39;, axis=1)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>wheel_base</th>
      <th>length</th>
      <th>width</th>
      <th>curb_weight</th>
      <th>engine_size</th>
      <th>horsepower</th>
      <th>city_mpg</th>
      <th>highway_mpg</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>symboling</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>wheel_base</th>
      <td>NaN</td>
      <td>0.879800</td>
      <td>0.810604</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>length</th>
      <td>0.879800</td>
      <td>NaN</td>
      <td>0.856586</td>
      <td>0.879958</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>width</th>
      <td>0.810604</td>
      <td>0.856586</td>
      <td>NaN</td>
      <td>0.869088</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>height</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>curb_weight</th>
      <td>NaN</td>
      <td>0.879958</td>
      <td>0.869088</td>
      <td>NaN</td>
      <td>0.859137</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>engine_size</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.859137</td>
      <td>NaN</td>
      <td>0.844174</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>bore</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>stroke</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>compression_ratio</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>horsepower</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.844174</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>peak_rpm</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>city_mpg</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.972683</td>
    </tr>
    <tr>
      <th>highway_mpg</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.972683</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>num_feats
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;symboling&#39;,
 &#39;wheel_base&#39;,
 &#39;length&#39;,
 &#39;width&#39;,
 &#39;height&#39;,
 &#39;curb_weight&#39;,
 &#39;engine_size&#39;,
 &#39;bore&#39;,
 &#39;stroke&#39;,
 &#39;compression_ratio&#39;,
 &#39;horsepower&#39;,
 &#39;peak_rpm&#39;,
 &#39;city_mpg&#39;,
 &#39;highway_mpg&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>#therefore:
num_feats = [&#39;symboling&#39;,
 &#39;wheel_base&#39;,
 &#39;height&#39;,
 &#39;engine_size&#39;,
 &#39;bore&#39;,
 &#39;stroke&#39;,
 &#39;compression_ratio&#39;,
 &#39;peak_rpm&#39;,
 &#39;city_mpg&#39;]


formula2 = &#39; + &#39;.join(num_feats)
formula2 = formula + &#39; + &#39; + formula2
formula2
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;price ~ C(make) + C(fuel_type) + C(aspiration) + C(num_of_doors) + C(body_style) + C(drive_wheels) + C(engine_location) + C(engine_type) + C(num_of_cylinders) + C(fuel_system) + symboling + wheel_base + height + engine_size + bore + stroke + compression_ratio + peak_rpm + city_mpg&#39;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>import statsmodels.formula.api as smf
X_train[&#39;price&#39;] = y_train
mod = smf.ols(formula=formula2, data=X_train)
model_ols = mod.fit()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/data/data-erick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy

</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model_ols.rsquared_adj
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.96003022206168109
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>ols_predictions = model_ols.predict(X_test)
ols_mse = np.mean((ols_predictions - y_test)**2)
ols_mse
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2602928.238875181
</pre></div></div>
</div>
<p>With an adjusted R2R2 score of 0.96 we can say that it is a really good model already!</p>
</div>
<div class="section" id="Adjusting-this-model---feature-selection">
<h3>Adjusting this model - feature selection<a class="headerlink" href="#Adjusting-this-model---feature-selection" title="Permalink to this headline">¶</a></h3>
<p>When we fit a linear regression model, we have to test the hypothesis that the evaluated coefficients for each regressor is actually zero.</p>
<p>In other words, we have: - <span class="math notranslate nohighlight">\(H_0\)</span>: the coefficient is zero - <span class="math notranslate nohighlight">\(H_1\)</span> : the coefficient is not zero</p>
<p>Therefore, let’s look into the p-values for each coefficient for each regressor to see if they shouldn’t be zero:</p>
<p><em>if a p-value of a given coefficient is larger than 5%, then we fail to reject the null hypothesis that the coefficient actually is zero</em></p>
<p>However, all p-values here are smaller than 5%, so no additional feature selection will be done.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model_ols.pvalues[model_ols.pvalues&gt;.05]
# we are not taking out make or engine_type just because a few rotten apples
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Series([], dtype: float64)
</pre></div></div>
</div>
</div>
<div class="section" id="Regularized-models---Ridge">
<h3>Regularized models - Ridge<a class="headerlink" href="#Regularized-models---Ridge" title="Permalink to this headline">¶</a></h3>
<p>Now lets fit some models that uses regularization for feature selection.</p>
<p>Ridge regression uses a penalty L2 factor for the least important regressors.</p>
<ul class="simple">
<li><p>L2: least squared deviation <span class="math notranslate nohighlight">\(resid = \sum{(y_i - \hat y_i)^2} + \lambda \sum{\beta^2}\)</span></p></li>
</ul>
<p>However, the least squares regularization is not robust: it is sensitive to outliers.</p>
<div class="section" id="Normalization">
<h4>Normalization<a class="headerlink" href="#Normalization" title="Permalink to this headline">¶</a></h4>
<p>Preprocessing will be required here: features normalization.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>X_train.drop(&#39;price&#39;, axis=1, inplace=True)
X_train_dummies = pd.get_dummies(X_train)
dummies_for_later = X_train_dummies.head() # will be used for predicting NA prices
X_test_dummies = pd.get_dummies(X_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/data/data-erick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  &#34;&#34;&#34;Entry point for launching an IPython kernel.
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

X_train_scaled = scaler.fit_transform(X_train_dummies)
X_test_scaled = scaler.transform(X_test_dummies)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.metrics import regression
import time

def regressor(model, set_train, set_test):
    start_time = time.time()
    model.fit(set_train, y_train)
    y_predictions = model.predict(set_test)

    print(str(model))
    print(&quot;\n--- %s seconds ---&quot; % round((time.time() - start_time),4))
    print(&quot;\nscore R2:&quot;, round(model.score(set_test, y_test),4))

    return print(&quot;MSE:&quot;, regression.mean_squared_error(y_test, y_predictions))
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.linear_model import Ridge

model = Ridge()
regressor(model, X_train_scaled, X_test_scaled)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=None, solver=&#39;auto&#39;, tol=0.001)

--- 0.0142 seconds ---

score R2: 0.9665
MSE: 2198273.41053
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model = Ridge(alpha=0.005)
regressor(model, X_train_scaled, X_test_scaled)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ridge(alpha=0.005, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=None, solver=&#39;auto&#39;, tol=0.001)

--- 0.0119 seconds ---

score R2: 0.967
MSE: 2162600.41987
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># this is it
model_ridge = Ridge(alpha=.005)
model_ridge.fit(X_train_scaled, y_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ridge(alpha=0.005, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=None, solver=&#39;auto&#39;, tol=0.001)
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Regularized-models---Lasso">
<h3>Regularized models - Lasso<a class="headerlink" href="#Regularized-models---Lasso" title="Permalink to this headline">¶</a></h3>
<p>Lasso regression uses a stronger penalty for the least important regressors, the L1.</p>
<p>That said, lasso will perform feature selection and it is not a stable solution.</p>
<ul class="simple">
<li><p>L1: least absolute deviation <span class="math notranslate nohighlight">\(resid = \sum{(y_i - \hat y_i)^2} + \lambda \sum{|\beta|}\)</span></p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.linear_model import Lasso

model = Lasso()
regressor(model, X_train_scaled, X_test_scaled)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
   normalize=False, positive=False, precompute=False, random_state=None,
   selection=&#39;cyclic&#39;, tol=0.0001, warm_start=False)

--- 0.7902 seconds ---

score R2: 0.9665
MSE: 2194754.54834
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model = Lasso(alpha=.5, max_iter=10000)
regressor(model, X_train_scaled, X_test_scaled)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Lasso(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=10000,
   normalize=False, positive=False, precompute=False, random_state=None,
   selection=&#39;cyclic&#39;, tol=0.0001, warm_start=False)

--- 0.8126 seconds ---

score R2: 0.9669
MSE: 2171336.23407
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model_lasso = Lasso(alpha=.5, max_iter=10000)
model_lasso.fit(X_train_scaled, y_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Lasso(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=10000,
   normalize=False, positive=False, precompute=False, random_state=None,
   selection=&#39;cyclic&#39;, tol=0.0001, warm_start=False)
</pre></div></div>
</div>
</div>
<div class="section" id="Huber-Regressor">
<h3>Huber Regressor<a class="headerlink" href="#Huber-Regressor" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.linear_model import HuberRegressor
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model = HuberRegressor(epsilon=1.5)
regressor(model, X_train_scaled, X_test_scaled)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
HuberRegressor(alpha=0.0001, epsilon=1.5, fit_intercept=True, max_iter=100,
        tol=1e-05, warm_start=False)

--- 0.4939 seconds ---

score R2: 0.9611
MSE: 2550082.29101
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[43]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model = HuberRegressor(epsilon=2)
regressor(model, X_train_scaled, X_test_scaled)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
HuberRegressor(alpha=0.0001, epsilon=2, fit_intercept=True, max_iter=100,
        tol=1e-05, warm_start=False)

--- 0.4371 seconds ---

score R2: 0.9636
MSE: 2382646.89839
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model_hubber = HuberRegressor(epsilon=2)
model_hubber.fit(X_train_scaled, y_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
HuberRegressor(alpha=0.0001, epsilon=2, fit_intercept=True, max_iter=100,
        tol=1e-05, warm_start=False)
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Analysis-of-MSE---mean-squared-error">
<h2>Analysis of MSE - mean squared error<a class="headerlink" href="#Analysis-of-MSE---mean-squared-error" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>ols_predictions = model_ols.predict(X_test)
ridge_predictions = model_ridge.predict(X_test_scaled)
lasso_predictions = model_lasso.predict(X_test_scaled)
huber_predictions = model_hubber.predict(X_test_scaled)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_comparisson = pd.DataFrame({&#39;model_ols&#39;: ols_predictions,
                               &#39;ridge&#39;: ridge_predictions,
                               &#39;lasso&#39;: lasso_predictions,
                               &#39;hubber&#39;: huber_predictions,
                              &#39;actual_price&#39;: y_test
                             })
df_comparisson.sample(10).round(2)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actual_price</th>
      <th>hubber</th>
      <th>lasso</th>
      <th>model_ols</th>
      <th>ridge</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>54</th>
      <td>7395.0</td>
      <td>6507.84</td>
      <td>6442.81</td>
      <td>7123.13</td>
      <td>6369.18</td>
    </tr>
    <tr>
      <th>15</th>
      <td>30760.0</td>
      <td>30072.94</td>
      <td>31635.43</td>
      <td>32517.46</td>
      <td>31701.34</td>
    </tr>
    <tr>
      <th>133</th>
      <td>12170.0</td>
      <td>14188.13</td>
      <td>14156.34</td>
      <td>14314.24</td>
      <td>14094.41</td>
    </tr>
    <tr>
      <th>88</th>
      <td>9279.0</td>
      <td>8970.82</td>
      <td>8789.88</td>
      <td>8316.30</td>
      <td>8832.57</td>
    </tr>
    <tr>
      <th>86</th>
      <td>8189.0</td>
      <td>8674.67</td>
      <td>8810.97</td>
      <td>8743.16</td>
      <td>8858.31</td>
    </tr>
    <tr>
      <th>83</th>
      <td>14869.0</td>
      <td>13604.54</td>
      <td>13845.94</td>
      <td>13046.94</td>
      <td>13818.13</td>
    </tr>
    <tr>
      <th>2</th>
      <td>16500.0</td>
      <td>15972.18</td>
      <td>16128.17</td>
      <td>15872.97</td>
      <td>16166.39</td>
    </tr>
    <tr>
      <th>0</th>
      <td>13495.0</td>
      <td>15111.94</td>
      <td>15152.75</td>
      <td>15325.00</td>
      <td>15179.90</td>
    </tr>
    <tr>
      <th>73</th>
      <td>40960.0</td>
      <td>40341.01</td>
      <td>42221.00</td>
      <td>44095.96</td>
      <td>42389.64</td>
    </tr>
    <tr>
      <th>0</th>
      <td>13495.0</td>
      <td>15111.94</td>
      <td>15152.75</td>
      <td>15325.00</td>
      <td>15179.90</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[47]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_comparisson.describe().round(2) # min and max prices are ok
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[47]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actual_price</th>
      <th>hubber</th>
      <th>lasso</th>
      <th>model_ols</th>
      <th>ridge</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1961.00</td>
      <td>1961.00</td>
      <td>1961.00</td>
      <td>1961.00</td>
      <td>1961.00</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>13321.54</td>
      <td>13240.38</td>
      <td>13325.40</td>
      <td>13320.58</td>
      <td>13325.26</td>
    </tr>
    <tr>
      <th>std</th>
      <td>8097.30</td>
      <td>7761.66</td>
      <td>7947.07</td>
      <td>7927.73</td>
      <td>7959.52</td>
    </tr>
    <tr>
      <th>min</th>
      <td>5118.00</td>
      <td>4699.08</td>
      <td>4450.71</td>
      <td>3240.36</td>
      <td>4386.02</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>7738.00</td>
      <td>7590.31</td>
      <td>7630.98</td>
      <td>7580.33</td>
      <td>7554.66</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>10198.00</td>
      <td>10750.51</td>
      <td>10839.58</td>
      <td>10685.36</td>
      <td>10827.57</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>16558.00</td>
      <td>16347.94</td>
      <td>16596.28</td>
      <td>16551.04</td>
      <td>16489.08</td>
    </tr>
    <tr>
      <th>max</th>
      <td>45400.00</td>
      <td>40341.01</td>
      <td>42221.00</td>
      <td>44095.96</td>
      <td>42389.64</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>def get_mse(model):
    return np.mean((df_comparisson[model] - df_comparisson.actual_price)**2)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>all_mse = pd.Series([get_mse(&#39;model_ols&#39;),
                     get_mse(&#39;ridge&#39;),
                     get_mse(&#39;lasso&#39;), get_mse(&#39;hubber&#39;)],
                   index=[&#39;model_ols&#39;, &#39;ridge&#39;, &#39;lasso&#39;, &#39;hubber&#39;])
all_mse.sort_values()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ridge        2.162600e+06
lasso        2.171336e+06
hubber       2.382647e+06
model_ols    2.718515e+06
dtype: float64
</pre></div></div>
</div>
</div>
<div class="section" id="Analysis-of-variance-explained:-R^2">
<h2>Analysis of variance explained: <span class="math notranslate nohighlight">\(R^2\)</span><a class="headerlink" href="#Analysis-of-variance-explained:-R^2" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[50]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>all_r2adj = pd.Series([model_ols.rsquared_adj,
                       model_ridge.score(X_test_scaled,y_test),
                       model_lasso.score(X_test_scaled, y_test),
                       model_hubber.score(X_test_scaled, y_test)
                      ],
          index=[&#39;model_ols&#39;, &#39;model_ridge&#39;, &#39;model_lasso&#39;, &#39;model_hubber&#39;])

all_r2adj.sort_values(ascending=False)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[50]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
model_ridge     0.967000
model_lasso     0.966866
model_hubber    0.963642
model_ols       0.957882
dtype: float64
</pre></div></div>
</div>
</div>
<div class="section" id="Residual-analysis">
<h2>Residual analysis<a class="headerlink" href="#Residual-analysis" title="Permalink to this headline">¶</a></h2>
<p>In a good model, what we should expect from the residuals: - their mean should be zero - they should be homoscedastic - they should be normal - they should have no correlation with the fitted values - they should have no correlation with any of the features</p>
<div class="section" id="Residual-mean">
<h3>Residual mean<a class="headerlink" href="#Residual-mean" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[51]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># OLS
model_ols.resid.mean()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[51]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
5.78165549903096e-09
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[52]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Ridge
model_ridge_resids = model_ridge.predict(X_train_scaled) - y_train
model_ridge_resids.mean() # good!
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[52]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-3.816629552082824e-13
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[53]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Lasso
model_lasso_resids = model_lasso.predict(X_train_scaled) - y_train
model_lasso_resids.mean() # good!
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[53]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-3.1393808187983397e-12
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[54]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Hubber
model_hubber_resids = model_hubber.predict(X_train_scaled) - y_train
model_hubber_resids.mean() # nope!
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[54]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-85.61977381445658
</pre></div></div>
</div>
</div>
<div class="section" id="Residuals-vs-fitted-values">
<h3>Residuals vs fitted values<a class="headerlink" href="#Residuals-vs-fitted-values" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[55]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from numpy.polynomial.polynomial import polyfit

plt.figure(figsize=(12,10))
plt.subplot(2, 2, 1)
plt.title(&#39;fitted price vs resids for all models&#39;)
plt.scatter(model_ols.fittedvalues, model_ols.resid, c=&quot;g&quot;, alpha=0.5, label=&quot;OLS model&quot;)
b, m = polyfit(model_ols.fittedvalues, model_ols.resid, 1)
plt.plot(model_ols.fittedvalues, b + m * model_ols.fittedvalues, &#39;-&#39;)
plt.xlabel(&quot;&quot;)
plt.ylabel(&quot;&quot;)
plt.legend(loc=2)


plt.subplot(2, 2, 2)
plt.scatter(model_ridge.predict(X_train_scaled), model_ridge_resids, c=&quot;b&quot;, alpha=0.5, label=&quot;Ridge model&quot;)
b, m = polyfit(model_ridge.predict(X_train_scaled), model_ridge_resids, 1)
plt.plot(model_ridge.predict(X_train_scaled), b + m * model_ridge.predict(X_train_scaled), &#39;-&#39;)
plt.xlabel(&quot;&quot;)
plt.ylabel(&quot;&quot;)
plt.legend(loc=2)


plt.subplot(2, 2, 3)
plt.scatter(model_lasso.predict(X_train_scaled), model_lasso_resids, c=&quot;y&quot;, alpha=0.5, label=&quot;Lasso model&quot;)
b, m = polyfit(model_lasso.predict(X_train_scaled), model_lasso_resids, 1)
plt.plot(model_lasso.predict(X_train_scaled), b + m * model_lasso.predict(X_train_scaled), &#39;-&#39;)
plt.xlabel(&quot;&quot;)
plt.ylabel(&quot;&quot;)
plt.legend(loc=2)


plt.subplot(2, 2, 4)
plt.scatter(model_hubber.predict(X_train_scaled), model_hubber_resids, c=&quot;y&quot;, alpha=0.5, label=&quot;Hubber model&quot;)
b, m = polyfit(model_hubber.predict(X_train_scaled), model_hubber_resids, 1)
plt.plot(model_hubber.predict(X_train_scaled), b + m * model_hubber.predict(X_train_scaled), &#39;-&#39;)
plt.xlabel(&quot;&quot;)
plt.ylabel(&quot;&quot;)
plt.legend(loc=2)

plt.tight_layout()
plt.show()

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/auto-1-challenge-part2_72_0.png" src="_images/auto-1-challenge-part2_72_0.png" />
</div>
</div>
<p>Hubber model residuals seems to have some correlation with <span class="math notranslate nohighlight">\(\hat y\)</span></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[56]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from scipy.stats.stats import pearsonr

pearsonr(model_hubber.predict(X_train_scaled), model_hubber_resids)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[56]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(-0.12243993567552305, 1.4273919551813508e-27)
</pre></div></div>
</div>
<p>Nope, all ok for the Hubber model</p>
</div>
<div class="section" id="Testing-residuals-for-normality">
<h3>Testing residuals for normality<a class="headerlink" href="#Testing-residuals-for-normality" title="Permalink to this headline">¶</a></h3>
<p>The Shapiro’s test tests the null hypothesis of normality:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[57]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># OLS
import scipy.stats as st
st.shapiro(model_ols.resid) # normal!
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/data/data-erick/anaconda3/lib/python3.6/site-packages/scipy/stats/morestats.py:1326: UserWarning: p-value may not be accurate for N &gt; 5000.
  warnings.warn(&#34;p-value may not be accurate for N &gt; 5000.&#34;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[57]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.9438661336898804, 0.0)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Ridge
st.shapiro(model_ridge_resids) # normal...
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/data/data-erick/anaconda3/lib/python3.6/site-packages/scipy/stats/morestats.py:1326: UserWarning: p-value may not be accurate for N &gt; 5000.
  warnings.warn(&#34;p-value may not be accurate for N &gt; 5000.&#34;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.9460887312889099, 0.0)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[59]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Lasso
st.shapiro(model_lasso_resids) # normal too...
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/data/data-erick/anaconda3/lib/python3.6/site-packages/scipy/stats/morestats.py:1326: UserWarning: p-value may not be accurate for N &gt; 5000.
  warnings.warn(&#34;p-value may not be accurate for N &gt; 5000.&#34;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[59]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.9407504796981812, 0.0)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[60]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># Hubber
st.shapiro(model_hubber_resids) # normal too...
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/data/data-erick/anaconda3/lib/python3.6/site-packages/scipy/stats/morestats.py:1326: UserWarning: p-value may not be accurate for N &gt; 5000.
  warnings.warn(&#34;p-value may not be accurate for N &gt; 5000.&#34;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[60]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.8604577779769897, 0.0)
</pre></div></div>
</div>
</div>
<div class="section" id="Correlation-between-residuals-and-features">
<h3>Correlation between residuals and features<a class="headerlink" href="#Correlation-between-residuals-and-features" title="Permalink to this headline">¶</a></h3>
<p>In a good model, residuals cannot be correlated to any feature.</p>
<p>Lets check that for the Ridge model:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[61]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from scipy.stats.stats import pearsonr


all_num_feats = list(X_train.describe().columns)
for feat in all_num_feats:
    print(feat, &quot;\n&quot;, pearsonr(X_train[feat], model_ridge_resids))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
symboling
 (3.6441610271369855e-06, 0.99974258919751702)
wheel_base
 (-2.0675596464059233e-05, 0.99853955019311291)
length
 (2.2590804097798883e-05, 0.99840426694859197)
width
 (-1.7772296922306348e-05, 0.99874462857613455)
height
 (8.7466404849492928e-06, 0.99938216857618778)
curb_weight
 (-3.504893907803107e-05, 0.9975242714796041)
engine_size
 (-7.349379064926162e-05, 0.99480869645886716)
bore
 (1.2181498141385697e-05, 0.99913954255004234)
stroke
 (7.9863932311714522e-06, 0.99943586935799111)
compression_ratio
 (2.6364431257605819e-05, 0.99813771200073198)
horsepower
 (1.9678279487423009e-06, 0.99986099962751818)
peak_rpm
 (-1.371111023920585e-05, 0.99903149594698415)
city_mpg
 (4.8072830800238043e-06, 0.99966043070927313)
highway_mpg
 (-1.4047195296974865e-05, 0.99900775626311067)
</pre></div></div>
</div>
<p>All ok here: there is no correlation between resids and any of the features</p>
</div>
<div class="section" id="Correlation-between-residuals-and-\hat-y">
<h3>Correlation between residuals and <span class="math notranslate nohighlight">\(\hat y\)</span><a class="headerlink" href="#Correlation-between-residuals-and-\hat-y" title="Permalink to this headline">¶</a></h3>
<p>In a good model, residuals cannot be correlated to the fitted values.</p>
<p>We have already saw before that the Ridge is ok in his regard:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[62]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from scipy.stats.stats import pearsonr
pearsonr(model_ridge.predict(X_train_scaled), model_ridge_resids)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[62]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(-0.00010617461659072249, 0.992500312880084)
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Fitted-values-distribution-analysis">
<h2>Fitted values distribution analysis<a class="headerlink" href="#Fitted-values-distribution-analysis" title="Permalink to this headline">¶</a></h2>
<p>We expect that the fitted values follows the same distribution of the original prices.</p>
<p>Lets see about that for the Ridge Model:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[63]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>import matplotlib.pyplot as plt

fig, (ax, ax2) = plt.subplots(ncols=2, sharey=False)

X_scaled = pd.get_dummies(X)
X_scaled = scaler.transform(X_scaled)
all_prices_pred = model_ridge.predict(X_scaled)

pd.Series(all_prices_pred).plot(kind=&#39;kde&#39;, legend=False, ax=ax,  figsize=(14,7), title=&#39;fitted y&#39;)
pd.Series(y).plot(kind=&#39;kde&#39;, legend=False, figsize=(14,7), title=&#39;original y&#39;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[63]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f29ea391cc0&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/auto-1-challenge-part2_86_1.png" src="_images/auto-1-challenge-part2_86_1.png" />
</div>
</div>
</div>
<div class="section" id="Most-important-features">
<h2>Most important features<a class="headerlink" href="#Most-important-features" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Ridge">
<h3>Ridge<a class="headerlink" href="#Ridge" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[64]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_coef_ridge = pd.DataFrame({&#39;feats&#39;: pd.get_dummies(X).columns,
                              &#39;coefs_abs&#39;: np.abs(np.round(model_ridge.coef_,2)),
                              &#39;coefs_value&#39;: np.round(model_ridge.coef_,2)})
df_coef_ridge[~df_coef_ridge.feats.str.startswith(&#39;make&#39;)].sort_values(&#39;coefs_abs&#39;, ascending=False).head(10)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[64]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coefs_abs</th>
      <th>coefs_value</th>
      <th>feats</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>26537.49</td>
      <td>26537.49</td>
      <td>engine_size</td>
    </tr>
    <tr>
      <th>5</th>
      <td>16505.82</td>
      <td>16505.82</td>
      <td>curb_weight</td>
    </tr>
    <tr>
      <th>9</th>
      <td>15195.11</td>
      <td>-15195.11</td>
      <td>compression_ratio</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9591.46</td>
      <td>-9591.46</td>
      <td>length</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8486.31</td>
      <td>8486.31</td>
      <td>wheel_base</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7495.75</td>
      <td>7495.75</td>
      <td>width</td>
    </tr>
    <tr>
      <th>11</th>
      <td>6047.05</td>
      <td>6047.05</td>
      <td>peak_rpm</td>
    </tr>
    <tr>
      <th>13</th>
      <td>5726.00</td>
      <td>5726.00</td>
      <td>highway_mpg</td>
    </tr>
    <tr>
      <th>7</th>
      <td>5435.42</td>
      <td>-5435.42</td>
      <td>bore</td>
    </tr>
    <tr>
      <th>59</th>
      <td>5185.45</td>
      <td>5185.45</td>
      <td>num_of_cylinders_three</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="Lasso">
<h3>Lasso<a class="headerlink" href="#Lasso" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[65]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_coef_lasso = pd.DataFrame({&#39;feats&#39;: pd.get_dummies(X).columns,
                              &#39;coefs_abs&#39;: np.abs(np.round(model_lasso.coef_,2)),
                              &#39;coefs_value&#39;: np.round(model_lasso.coef_,2)})
df_coef_lasso[~df_coef_lasso.feats.str.startswith(&#39;make&#39;)].sort_values(&#39;coefs_abs&#39;, ascending=False).head(10)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[65]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coefs_abs</th>
      <th>coefs_value</th>
      <th>feats</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>24796.37</td>
      <td>24796.37</td>
      <td>engine_size</td>
    </tr>
    <tr>
      <th>5</th>
      <td>15886.63</td>
      <td>15886.63</td>
      <td>curb_weight</td>
    </tr>
    <tr>
      <th>9</th>
      <td>12267.44</td>
      <td>-12267.44</td>
      <td>compression_ratio</td>
    </tr>
    <tr>
      <th>35</th>
      <td>10125.39</td>
      <td>10125.39</td>
      <td>fuel_type_diesel</td>
    </tr>
    <tr>
      <th>48</th>
      <td>9559.07</td>
      <td>-9559.07</td>
      <td>engine_location_front</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8650.65</td>
      <td>-8650.65</td>
      <td>length</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7815.88</td>
      <td>7815.88</td>
      <td>wheel_base</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7369.02</td>
      <td>7369.02</td>
      <td>width</td>
    </tr>
    <tr>
      <th>59</th>
      <td>6623.57</td>
      <td>6623.57</td>
      <td>num_of_cylinders_three</td>
    </tr>
    <tr>
      <th>11</th>
      <td>5831.79</td>
      <td>5831.79</td>
      <td>peak_rpm</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="OLS">
<h3>OLS<a class="headerlink" href="#OLS" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[66]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>index = model_ols.pvalues[model_ols.pvalues&lt;.05].index

coefs = model_ols.params[index]

df_coef_ols = pd.DataFrame({&#39;coefs_abs&#39;: np.abs(np.round(coefs,2)),
                            &#39;coef_value&#39;: np.round(coefs,2),
                            &#39;feats&#39;: coefs.index})

df_coef_ols[~df_coef_ols.feats.str.startswith(&#39;make&#39;)].sort_values(&#39;coefs_abs&#39;, ascending=False).head(10)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[66]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coef_value</th>
      <th>coefs_abs</th>
      <th>feats</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>C(fuel_system)[T.idi]</th>
      <td>10350.37</td>
      <td>10350.37</td>
      <td>C(fuel_system)[T.idi]</td>
    </tr>
    <tr>
      <th>C(fuel_system)[T.spfi]</th>
      <td>7076.78</td>
      <td>7076.78</td>
      <td>C(fuel_system)[T.spfi]</td>
    </tr>
    <tr>
      <th>C(make)[T.porsche]</th>
      <td>6833.08</td>
      <td>6833.08</td>
      <td>C(make)[T.porsche]</td>
    </tr>
    <tr>
      <th>C(num_of_cylinders)[T.twelve]</th>
      <td>-6420.79</td>
      <td>6420.79</td>
      <td>C(num_of_cylinders)[T.twelve]</td>
    </tr>
    <tr>
      <th>Intercept</th>
      <td>6184.20</td>
      <td>6184.20</td>
      <td>Intercept</td>
    </tr>
    <tr>
      <th>C(make)[T.isuzu]</th>
      <td>-5587.34</td>
      <td>5587.34</td>
      <td>C(make)[T.isuzu]</td>
    </tr>
    <tr>
      <th>C(make)[T.bmw]</th>
      <td>5472.98</td>
      <td>5472.98</td>
      <td>C(make)[T.bmw]</td>
    </tr>
    <tr>
      <th>C(make)[T.plymouth]</th>
      <td>-4686.91</td>
      <td>4686.91</td>
      <td>C(make)[T.plymouth]</td>
    </tr>
    <tr>
      <th>C(make)[T.dodge]</th>
      <td>-4607.82</td>
      <td>4607.82</td>
      <td>C(make)[T.dodge]</td>
    </tr>
    <tr>
      <th>C(make)[T.mercedes-benz]</th>
      <td>4473.15</td>
      <td>4473.15</td>
      <td>C(make)[T.mercedes-benz]</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
</div>
<div class="section" id="Comparing-the-models---conclusions">
<h2>Comparing the models - conclusions<a class="headerlink" href="#Comparing-the-models---conclusions" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>residual analysis shows better results for the ridge and lasso models: their residual means are closer to zero (not normal though)</p></li>
<li><p>all models have no correlation between fitted values and residuals</p></li>
<li><p>MSE analysis shows better results for the Ridge model: smallest MSE</p></li>
<li><p><span class="math notranslate nohighlight">\(R^2\)</span> analysis shows better results for the Ridge model</p></li>
<li><p>OLS model gets a pretty close score to Ridge but it uses only 20 features, while Ridge uses 24</p></li>
</ul>
</div>
<div class="section" id="Machine-Learning-models">
<h2>Machine Learning models<a class="headerlink" href="#Machine-Learning-models" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Decision-Trees">
<h3>Decision Trees<a class="headerlink" href="#Decision-Trees" title="Permalink to this headline">¶</a></h3>
<p>We could try fitting machine learning models too. Lets quickly train an decision tree regressor to compare to our previous models:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[97]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.tree import DecisionTreeRegressor

model = DecisionTreeRegressor(random_state=95276, min_samples_leaf=5,
                             max_depth=15, max_leaf_nodes=185)
#model = DecisionTreeRegressor(random_state=95276)
regressor(model, X_train_dummies, X_test_dummies)



</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
DecisionTreeRegressor(criterion=&#39;mse&#39;, max_depth=15, max_features=None,
           max_leaf_nodes=185, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=5,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           presort=False, random_state=95276, splitter=&#39;best&#39;)

--- 0.0592 seconds ---

score R2: 0.9988
MSE: 78275.8642876
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[99]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model_tree = DecisionTreeRegressor(random_state=95276, min_samples_leaf=5,
                             max_depth=15, max_leaf_nodes=185)
model_tree.fit(X_train_dummies, y_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[99]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
DecisionTreeRegressor(criterion=&#39;mse&#39;, max_depth=15, max_features=None,
           max_leaf_nodes=185, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=5,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           presort=False, random_state=95276, splitter=&#39;best&#39;)
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[102]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model_tree_predictions = model_tree.predict(X_test_dummies)
model_tree_r2 = model_tree.score(X_test_dummies, y_test)
model_tree_mse = regression.mean_squared_error(y_test, model_tree_predictions)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>tree_predictions = tree.predict(X_test_scaled)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Random-Forests">
<h3>Random Forests<a class="headerlink" href="#Random-Forests" title="Permalink to this headline">¶</a></h3>
<p>Random Forests are ensemble machine learning methods.</p>
<p>Ensemble methods are a combination of predictions from several learning algorithm. This makes them robust (not sensitive to outliers) and with improved power of generalization.</p>
<p>In particular, Random Forests is a averaging ensemble method: several estimators are built independently and then the predictions are averaged. This reduces variance and thus they perform better than any single estimator</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[132]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(random_state=95276, n_jobs=3, max_features=5,
                             n_estimators=100)
regressor(model, X_train_dummies, X_test_dummies)

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,
           max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=100, n_jobs=3, oob_score=False, random_state=95276,
           verbose=0, warm_start=False)

--- 0.4373 seconds ---

score R2: 0.9988
MSE: 78162.6694765
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[133]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model_rf = RandomForestRegressor(random_state=95276, n_jobs=3, max_features=5,
                             n_estimators=100)
model_rf.fit(X_train_dummies, y_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[133]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RandomForestRegressor(bootstrap=True, criterion=&#39;mse&#39;, max_depth=None,
           max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=1,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           n_estimators=100, n_jobs=3, oob_score=False, random_state=95276,
           verbose=0, warm_start=False)
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[134]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model_rf_predictions = model_rf.predict(X_test_dummies)
model_rf_r2 = model_rf.score(X_test_dummies, y_test)
model_rf_mse = regression.mean_squared_error(y_test, model_rf_predictions)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Gradient-tree-boosting">
<h3>Gradient tree boosting<a class="headerlink" href="#Gradient-tree-boosting" title="Permalink to this headline">¶</a></h3>
<p>Gradient tree boosting are ensemble machine learning methods also, but this time we have the boosting class: several weak models are combined to produce a powerful estimator with reduced bias.</p>
<p>This method is very robust because it uses regularization.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[168]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.ensemble import GradientBoostingRegressor
model = GradientBoostingRegressor(random_state=95276, max_features=10, max_depth=15,
                                 alpha=.3, min_samples_leaf=5, min_samples_split=5,
                                  n_estimators=150)
regressor(model, X_train_dummies, X_test_dummies)

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
GradientBoostingRegressor(alpha=0.3, criterion=&#39;friedman_mse&#39;, init=None,
             learning_rate=0.1, loss=&#39;ls&#39;, max_depth=15, max_features=10,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=5,
             min_samples_split=5, min_weight_fraction_leaf=0.0,
             n_estimators=150, presort=&#39;auto&#39;, random_state=95276,
             subsample=1.0, verbose=0, warm_start=False)

--- 4.1596 seconds ---

score R2: 0.9988
MSE: 78275.8674881
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[169]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model_gb = GradientBoostingRegressor(random_state=95276, max_features=10, max_depth=15,
                                 alpha=.3, min_samples_leaf=5, min_samples_split=5,
                                  n_estimators=150)
model_gb.fit(X_train_dummies, y_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[169]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
GradientBoostingRegressor(alpha=0.3, criterion=&#39;friedman_mse&#39;, init=None,
             learning_rate=0.1, loss=&#39;ls&#39;, max_depth=15, max_features=10,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=5,
             min_samples_split=5, min_weight_fraction_leaf=0.0,
             n_estimators=150, presort=&#39;auto&#39;, random_state=95276,
             subsample=1.0, verbose=0, warm_start=False)
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[170]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model_gb_predictions = model_gb.predict(X_test_dummies)
model_gb_r2 = model_gb.score(X_test_dummies, y_test)
model_gb_mse = regression.mean_squared_error(y_test, model_gb_predictions)
</pre></div>
</div>
</div>
</div>
<div class="section" id="AdaBoost">
<h3>AdaBoost<a class="headerlink" href="#AdaBoost" title="Permalink to this headline">¶</a></h3>
<p>Adaboost is another ensemble machine learning method of the boosting class</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[182]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>from sklearn.ensemble import AdaBoostRegressor
model = AdaBoostRegressor(random_state=95276, n_estimators=100, base_estimator=model_tree,
                         learning_rate=.2)
regressor(model, X_train_dummies, X_test_dummies)

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion=&#39;mse&#39;, max_depth=15, max_features=None,
           max_leaf_nodes=185, min_impurity_decrease=0.0,
           min_impurity_split=None, min_samples_leaf=5,
           min_samples_split=2, min_weight_fraction_leaf=0.0,
           presort=False, random_state=95276, splitter=&#39;best&#39;),
         learning_rate=0.2, loss=&#39;linear&#39;, n_estimators=100,
         random_state=95276)

--- 1.1027 seconds ---

score R2: 0.9988
MSE: 78309.3163565
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
<p>Even without tunning any parameters for the model, we could achieve a really good MSE and <span class="math notranslate nohighlight">\(R^2\)</span> score. This looks promising.</p>
</div>
<div class="section" id="Adding-features">
<h3>Adding features<a class="headerlink" href="#Adding-features" title="Permalink to this headline">¶</a></h3>
<p>Another thing to consider: adding information about the age and original price of each car. This certainly would help getting better predictions.</p>
<p>As a matter of fact, the <em>normalized-losses</em> feature could be pointing that way. Let’s quickly build another model that will consider it:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[66]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>#All of the part 1, cleaning, in one function!
def make_df_set(df, cat=1, dropna=1):

    df.columns = df.columns.str.replace(&quot;-&quot;, &quot;_&quot;)
    df.replace(to_replace=&quot;?&quot;, value= np.NaN, inplace=True)

    if dropna==1:
        df.dropna(inplace=True)

    df.drive_wheels.replace(&quot;4wd&quot;, &quot;fwd&quot;, inplace=True)
    df.engine_type.replace(&#39;dohcv&#39;, &#39;dohc&#39;, inplace=True)

    rep_map = {&#39;mfi&#39;: &#39;mpfi&#39;}

    df.fuel_system.replace(rep_map, inplace=True)

    float_cols = [&#39;symboling&#39;, &#39;normalized_losses&#39;,  &#39;wheel_base&#39;, &#39;length&#39;,
              &#39;width&#39;, &#39;height&#39;, &#39;curb_weight&#39;, &#39;engine_size&#39;,
              &#39;bore&#39;, &#39;stroke&#39;, &#39;compression_ratio&#39;, &#39;horsepower&#39;, &#39;peak_rpm&#39;,
              &#39;city_mpg&#39;, &#39;highway_mpg&#39;, &#39;price&#39;]

    for col in float_cols:
        df[col] = df[col].astype(&#39;float&#39;)

    category_cols = [&#39;make&#39;, &#39;fuel_type&#39;, &#39;aspiration&#39;,&#39;num_of_cylinders&#39;,
           &#39;num_of_doors&#39;, &#39;body_style&#39;, &#39;drive_wheels&#39;, &#39;engine_location&#39;,
           &#39;fuel_system&#39;, &#39;engine_type&#39;]

    if cat==1:
        for col in category_cols:
            df[col] = df[col].astype(&#39;category&#39;)

    return df
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[67]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df = pd.read_csv(&quot;Auto1-DS-TestData.csv&quot;)

df = make_df_set(df)
df = df.sample(10000, replace=True) # for balancing classes
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[68]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>X = df
y = df.price
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[69]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,
                                                    random_state=95276, stratify=y)


</pre></div>
</div>
</div>
</div>
<div class="section" id="id1">
<h3>OLS<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[70]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>formula3 = formula2 + &#39; + normalized_losses&#39;
formula3
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[70]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;price ~ C(make) + C(fuel_type) + C(aspiration) + C(num_of_doors) + C(body_style) + C(drive_wheels) + C(engine_location) + C(engine_type) + C(num_of_cylinders) + C(fuel_system) + symboling + wheel_base + height + engine_size + bore + stroke + compression_ratio + peak_rpm + city_mpg + normalized_losses&#39;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[71]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>mod = smf.ols(formula=formula3, data=X_train)

model_ols_nlosses = mod.fit()
model_ols_nlosses.rsquared_adj
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[71]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.96696497039418172
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[72]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>prices_pred_model_ols_nlosses = model_ols_nlosses.predict(X_test)
</pre></div>
</div>
</div>
</div>
<div class="section" id="id2">
<h3>Ridge<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[73]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>########
scaler2 = MinMaxScaler()

X_train.drop(&#39;price&#39;, axis=1, inplace=True)
X_test.drop(&#39;price&#39;, axis=1, inplace=True)

X_train_dummies = pd.get_dummies(X_train)
X_test_dummies = pd.get_dummies(X_test)

X_train_scaled = scaler2.fit_transform(X_train_dummies)
X_test_scaled = scaler2.transform(X_test_dummies)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/data/data-erick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  after removing the cwd from sys.path.
/data/data-erick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  &#34;&#34;&#34;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[74]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># using this cell to explore alpha values
model = Ridge(alpha=.06)
regressor(model, X_train_scaled, X_test_scaled)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ridge(alpha=0.06, copy_X=True, fit_intercept=True, max_iter=None,
   normalize=False, random_state=None, solver=&#39;auto&#39;, tol=0.001)

--- 0.0126 seconds ---

score R2: 0.973
MSE: 914660.316789
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[75]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>model_ridge_nlosses = Ridge(alpha=.06)
model_ridge_nlosses.fit(X_train_scaled, y_train)
model_ridge_nlosses.score(X_train_scaled, y_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[75]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.97339171276582726
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[76]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>ridge_pred_nlosses = model_ridge_nlosses.predict(X_test_scaled)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Decision-tree">
<h3>Decision tree<a class="headerlink" href="#Decision-tree" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[77]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span># one last look at decision trees
tree_nlosses = DecisionTreeRegressor(random_state=95276).fit(X_train_dummies, y_train)
tree_nlosses_pred = tree_nlosses.predict(X_test_dummies)
round(tree_nlosses.score(X_test_dummies, y_test),2) # WOW!
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[77]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1.0
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[78]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_comparisson = pd.DataFrame({&#39;ols_nlosses&#39;: prices_pred_model_ols_nlosses,
                              &#39;ridge_nlosses&#39;: ridge_pred_nlosses,
                               &#39;tree_nlosses&#39;: tree_nlosses_pred,
                                 &#39;actual_price&#39;: y_test
                                })

df_comparisson.sample(20).round(2)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[78]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actual_price</th>
      <th>ols_nlosses</th>
      <th>ridge_nlosses</th>
      <th>tree_nlosses</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>87</th>
      <td>9279.0</td>
      <td>9795.10</td>
      <td>9872.35</td>
      <td>9279.00</td>
    </tr>
    <tr>
      <th>195</th>
      <td>13415.0</td>
      <td>15174.54</td>
      <td>15231.43</td>
      <td>13415.00</td>
    </tr>
    <tr>
      <th>95</th>
      <td>7799.0</td>
      <td>7139.65</td>
      <td>7234.07</td>
      <td>7799.00</td>
    </tr>
    <tr>
      <th>65</th>
      <td>18280.0</td>
      <td>15574.52</td>
      <td>15962.27</td>
      <td>18280.00</td>
    </tr>
    <tr>
      <th>85</th>
      <td>6989.0</td>
      <td>8346.15</td>
      <td>8372.50</td>
      <td>6989.00</td>
    </tr>
    <tr>
      <th>98</th>
      <td>8249.0</td>
      <td>7394.87</td>
      <td>7816.37</td>
      <td>8249.00</td>
    </tr>
    <tr>
      <th>149</th>
      <td>11694.0</td>
      <td>12262.58</td>
      <td>12103.81</td>
      <td>11694.00</td>
    </tr>
    <tr>
      <th>33</th>
      <td>6529.0</td>
      <td>7164.98</td>
      <td>7404.96</td>
      <td>6529.00</td>
    </tr>
    <tr>
      <th>135</th>
      <td>15510.0</td>
      <td>13910.27</td>
      <td>14294.12</td>
      <td>15510.00</td>
    </tr>
    <tr>
      <th>162</th>
      <td>9258.0</td>
      <td>7689.40</td>
      <td>7676.63</td>
      <td>9258.00</td>
    </tr>
    <tr>
      <th>170</th>
      <td>11199.0</td>
      <td>10412.51</td>
      <td>10733.48</td>
      <td>11199.00</td>
    </tr>
    <tr>
      <th>185</th>
      <td>8195.0</td>
      <td>8926.16</td>
      <td>8805.59</td>
      <td>8195.00</td>
    </tr>
    <tr>
      <th>112</th>
      <td>16900.0</td>
      <td>16469.29</td>
      <td>16420.88</td>
      <td>17439.72</td>
    </tr>
    <tr>
      <th>161</th>
      <td>8358.0</td>
      <td>7880.99</td>
      <td>7488.21</td>
      <td>8358.00</td>
    </tr>
    <tr>
      <th>36</th>
      <td>7295.0</td>
      <td>7736.52</td>
      <td>7038.64</td>
      <td>7295.00</td>
    </tr>
    <tr>
      <th>132</th>
      <td>11850.0</td>
      <td>13586.86</td>
      <td>13147.28</td>
      <td>11850.00</td>
    </tr>
    <tr>
      <th>54</th>
      <td>7395.0</td>
      <td>7744.56</td>
      <td>7332.85</td>
      <td>7395.00</td>
    </tr>
    <tr>
      <th>26</th>
      <td>7609.0</td>
      <td>6756.13</td>
      <td>7119.51</td>
      <td>7126.37</td>
    </tr>
    <tr>
      <th>72</th>
      <td>35056.0</td>
      <td>35056.00</td>
      <td>35053.98</td>
      <td>35056.00</td>
    </tr>
    <tr>
      <th>36</th>
      <td>7295.0</td>
      <td>7736.52</td>
      <td>7038.64</td>
      <td>7295.00</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[79]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_comparisson.describe().round(2) # checking for min and max prices here: problems for ols_nlosses!
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[79]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actual_price</th>
      <th>ols_nlosses</th>
      <th>ridge_nlosses</th>
      <th>tree_nlosses</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>2000.00</td>
      <td>2000.00</td>
      <td>2000.00</td>
      <td>2000.00</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>11403.52</td>
      <td>11404.34</td>
      <td>11405.45</td>
      <td>11407.24</td>
    </tr>
    <tr>
      <th>std</th>
      <td>5820.08</td>
      <td>5722.21</td>
      <td>5739.88</td>
      <td>5816.48</td>
    </tr>
    <tr>
      <th>min</th>
      <td>5118.00</td>
      <td>4953.09</td>
      <td>4787.97</td>
      <td>5118.00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>7395.00</td>
      <td>7273.15</td>
      <td>7411.94</td>
      <td>7349.00</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>9095.00</td>
      <td>9092.35</td>
      <td>9291.55</td>
      <td>9279.00</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>14399.00</td>
      <td>15161.67</td>
      <td>15050.32</td>
      <td>14399.00</td>
    </tr>
    <tr>
      <th>max</th>
      <td>35056.00</td>
      <td>35056.00</td>
      <td>35053.98</td>
      <td>35056.00</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[80]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>new_models_mse = pd.Series([get_mse(&#39;ols_nlosses&#39;), get_mse(&#39;ridge_nlosses&#39;),
                           get_mse(&#39;tree_nlosses&#39;)],
                   index=[&#39;ols_nlosses&#39;, &#39;ridge_nlosses&#39;, &#39;tree_nlosses&#39;])

all_mse_new = pd.concat([all_mse, new_models_mse])
all_mse_new.sort_values()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[80]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tree_nlosses     2.714063e+04
ridge_nlosses    9.146603e+05
ols_nlosses      1.125123e+06
ridge            2.027869e+06
lasso            2.035205e+06
hubber           2.268078e+06
model_ols        2.559538e+06
dtype: float64
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Final-thoughts">
<h2>Final thoughts<a class="headerlink" href="#Final-thoughts" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>adding information about normalized losses really helps the all the models!</p></li>
<li><p>machine learning with decision trees achieves the bests MSE</p></li>
<li><p>among the linear regression models, Ridge is the best one</p></li>
<li><p>OLS with feature selection should really be taken into consideration, because it achieves pretty close scores with less features</p></li>
<li><p>the prices predicted by all models follows a bimodal distribution, just like the original prices</p></li>
<li><p>with more time, additional supervised learning methods would be tested</p></li>
<li><p>with more time, data would be tested for outliers</p></li>
</ul>
</div>
<div class="section" id="Using-the-best-model-for-predicting-NA-prices">
<h2>Using the best model for predicting NA prices<a class="headerlink" href="#Using-the-best-model-for-predicting-NA-prices" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[81]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_predict = pd.read_csv(&quot;Auto1-DS-TestData.csv&quot;)
df_predict = make_df_set(df_predict, cat=0, dropna=0)

df_predict = df_predict[df_predict.price.isna()]
df_predict
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[81]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>normalized_losses</th>
      <th>make</th>
      <th>fuel_type</th>
      <th>aspiration</th>
      <th>num_of_doors</th>
      <th>body_style</th>
      <th>drive_wheels</th>
      <th>engine_location</th>
      <th>wheel_base</th>
      <th>...</th>
      <th>engine_size</th>
      <th>fuel_system</th>
      <th>bore</th>
      <th>stroke</th>
      <th>compression_ratio</th>
      <th>horsepower</th>
      <th>peak_rpm</th>
      <th>city_mpg</th>
      <th>highway_mpg</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>0.0</td>
      <td>NaN</td>
      <td>audi</td>
      <td>gas</td>
      <td>turbo</td>
      <td>two</td>
      <td>hatchback</td>
      <td>fwd</td>
      <td>front</td>
      <td>99.5</td>
      <td>...</td>
      <td>131.0</td>
      <td>mpfi</td>
      <td>3.13</td>
      <td>3.40</td>
      <td>7.0</td>
      <td>160.0</td>
      <td>5500.0</td>
      <td>16.0</td>
      <td>22.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>44</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>isuzu</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>94.5</td>
      <td>...</td>
      <td>90.0</td>
      <td>2bbl</td>
      <td>3.03</td>
      <td>3.11</td>
      <td>9.6</td>
      <td>70.0</td>
      <td>5400.0</td>
      <td>38.0</td>
      <td>43.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>45</th>
      <td>0.0</td>
      <td>NaN</td>
      <td>isuzu</td>
      <td>gas</td>
      <td>std</td>
      <td>four</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>94.5</td>
      <td>...</td>
      <td>90.0</td>
      <td>2bbl</td>
      <td>3.03</td>
      <td>3.11</td>
      <td>9.6</td>
      <td>70.0</td>
      <td>5400.0</td>
      <td>38.0</td>
      <td>43.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>129</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>porsche</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>hatchback</td>
      <td>rwd</td>
      <td>front</td>
      <td>98.4</td>
      <td>...</td>
      <td>203.0</td>
      <td>mpfi</td>
      <td>3.94</td>
      <td>3.11</td>
      <td>10.0</td>
      <td>288.0</td>
      <td>5750.0</td>
      <td>17.0</td>
      <td>28.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 26 columns</p>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[82]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>#Since all normalized_losses here are NAs,
#lets drop them and use the best model that doesn&#39;t consider them:
df = df_predict.drop(&#39;normalized_losses&#39;, axis=1).copy()
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[83]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df = pd.get_dummies(df)
df = df.reindex(columns = dummies_for_later.columns, fill_value=0)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[84]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[84]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>wheel_base</th>
      <th>length</th>
      <th>width</th>
      <th>height</th>
      <th>curb_weight</th>
      <th>engine_size</th>
      <th>bore</th>
      <th>stroke</th>
      <th>compression_ratio</th>
      <th>...</th>
      <th>num_of_cylinders_four</th>
      <th>num_of_cylinders_six</th>
      <th>num_of_cylinders_three</th>
      <th>num_of_cylinders_twelve</th>
      <th>fuel_system_1bbl</th>
      <th>fuel_system_2bbl</th>
      <th>fuel_system_idi</th>
      <th>fuel_system_mpfi</th>
      <th>fuel_system_spdi</th>
      <th>fuel_system_spfi</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>0.0</td>
      <td>99.5</td>
      <td>178.2</td>
      <td>67.9</td>
      <td>52.0</td>
      <td>3053.0</td>
      <td>131.0</td>
      <td>3.13</td>
      <td>3.40</td>
      <td>7.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>44</th>
      <td>1.0</td>
      <td>94.5</td>
      <td>155.9</td>
      <td>63.6</td>
      <td>52.0</td>
      <td>1874.0</td>
      <td>90.0</td>
      <td>3.03</td>
      <td>3.11</td>
      <td>9.6</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>45</th>
      <td>0.0</td>
      <td>94.5</td>
      <td>155.9</td>
      <td>63.6</td>
      <td>52.0</td>
      <td>1909.0</td>
      <td>90.0</td>
      <td>3.03</td>
      <td>3.11</td>
      <td>9.6</td>
      <td>...</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>129</th>
      <td>1.0</td>
      <td>98.4</td>
      <td>175.7</td>
      <td>72.3</td>
      <td>50.5</td>
      <td>3366.0</td>
      <td>203.0</td>
      <td>3.94</td>
      <td>3.11</td>
      <td>10.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 67 columns</p>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[85]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_scaled = scaler.transform(df)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[86]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>prices = model_ridge.predict(df_scaled)
prices
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[86]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([ 23092.16201465,   7466.7928181 ,   8236.34505236,  37058.91512718])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[87]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_predict[&#39;prices&#39;] = prices
df_predict
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[87]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>symboling</th>
      <th>normalized_losses</th>
      <th>make</th>
      <th>fuel_type</th>
      <th>aspiration</th>
      <th>num_of_doors</th>
      <th>body_style</th>
      <th>drive_wheels</th>
      <th>engine_location</th>
      <th>wheel_base</th>
      <th>...</th>
      <th>fuel_system</th>
      <th>bore</th>
      <th>stroke</th>
      <th>compression_ratio</th>
      <th>horsepower</th>
      <th>peak_rpm</th>
      <th>city_mpg</th>
      <th>highway_mpg</th>
      <th>price</th>
      <th>prices</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>0.0</td>
      <td>NaN</td>
      <td>audi</td>
      <td>gas</td>
      <td>turbo</td>
      <td>two</td>
      <td>hatchback</td>
      <td>fwd</td>
      <td>front</td>
      <td>99.5</td>
      <td>...</td>
      <td>mpfi</td>
      <td>3.13</td>
      <td>3.40</td>
      <td>7.0</td>
      <td>160.0</td>
      <td>5500.0</td>
      <td>16.0</td>
      <td>22.0</td>
      <td>NaN</td>
      <td>23092.162015</td>
    </tr>
    <tr>
      <th>44</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>isuzu</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>94.5</td>
      <td>...</td>
      <td>2bbl</td>
      <td>3.03</td>
      <td>3.11</td>
      <td>9.6</td>
      <td>70.0</td>
      <td>5400.0</td>
      <td>38.0</td>
      <td>43.0</td>
      <td>NaN</td>
      <td>7466.792818</td>
    </tr>
    <tr>
      <th>45</th>
      <td>0.0</td>
      <td>NaN</td>
      <td>isuzu</td>
      <td>gas</td>
      <td>std</td>
      <td>four</td>
      <td>sedan</td>
      <td>fwd</td>
      <td>front</td>
      <td>94.5</td>
      <td>...</td>
      <td>2bbl</td>
      <td>3.03</td>
      <td>3.11</td>
      <td>9.6</td>
      <td>70.0</td>
      <td>5400.0</td>
      <td>38.0</td>
      <td>43.0</td>
      <td>NaN</td>
      <td>8236.345052</td>
    </tr>
    <tr>
      <th>129</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>porsche</td>
      <td>gas</td>
      <td>std</td>
      <td>two</td>
      <td>hatchback</td>
      <td>rwd</td>
      <td>front</td>
      <td>98.4</td>
      <td>...</td>
      <td>mpfi</td>
      <td>3.94</td>
      <td>3.11</td>
      <td>10.0</td>
      <td>288.0</td>
      <td>5750.0</td>
      <td>17.0</td>
      <td>28.0</td>
      <td>NaN</td>
      <td>37058.915127</td>
    </tr>
  </tbody>
</table>
<p>4 rows × 27 columns</p>
</div></div>
</div>
<p>Is this prediction ok?</p>
<p>Lets see median prices from the original df:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[88]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>makers = list(df_predict.make.unique())
makers
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[88]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;audi&#39;, &#39;isuzu&#39;, &#39;porsche&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[89]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df = pd.read_csv(&quot;Auto1-DS-TestData.csv&quot;)
df = make_df_set(df, cat=0)

feats = [feat for feat in cat_feats if not feat.startswith(&#39;make&#39;)]
feats.insert(0, &#39;make&#39;)
feats # group by those feats and them look for median price
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[89]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;make&#39;,
 &#39;fuel_type&#39;,
 &#39;aspiration&#39;,
 &#39;num_of_doors&#39;,
 &#39;body_style&#39;,
 &#39;drive_wheels&#39;,
 &#39;engine_location&#39;,
 &#39;engine_type&#39;,
 &#39;num_of_cylinders&#39;,
 &#39;fuel_system&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[90]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_makers = df[df.make.isin(makers)]

df_medians = df_makers.groupby(feats)[[&#39;price&#39;]].median()
df_medians
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[90]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th>price</th>
    </tr>
    <tr>
      <th>make</th>
      <th>fuel_type</th>
      <th>aspiration</th>
      <th>num_of_doors</th>
      <th>body_style</th>
      <th>drive_wheels</th>
      <th>engine_location</th>
      <th>engine_type</th>
      <th>num_of_cylinders</th>
      <th>fuel_system</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">audi</th>
      <th rowspan="3" valign="top">gas</th>
      <th rowspan="2" valign="top">std</th>
      <th rowspan="2" valign="top">four</th>
      <th rowspan="2" valign="top">sedan</th>
      <th rowspan="2" valign="top">fwd</th>
      <th rowspan="2" valign="top">front</th>
      <th rowspan="2" valign="top">ohc</th>
      <th>five</th>
      <th>mpfi</th>
      <td>17580.0</td>
    </tr>
    <tr>
      <th>four</th>
      <th>mpfi</th>
      <td>13950.0</td>
    </tr>
    <tr>
      <th>turbo</th>
      <th>four</th>
      <th>sedan</th>
      <th>fwd</th>
      <th>front</th>
      <th>ohc</th>
      <th>five</th>
      <th>mpfi</th>
      <td>23875.0</td>
    </tr>
    <tr>
      <th>porsche</th>
      <th>gas</th>
      <th>std</th>
      <th>two</th>
      <th>hatchback</th>
      <th>rwd</th>
      <th>front</th>
      <th>ohc</th>
      <th>four</th>
      <th>mpfi</th>
      <td>22018.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[91]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>df_predict[[&#39;make&#39;, &#39;aspiration&#39;, &#39;prices&#39;]]
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[91]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>make</th>
      <th>aspiration</th>
      <th>prices</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>audi</td>
      <td>turbo</td>
      <td>23092.162015</td>
    </tr>
    <tr>
      <th>44</th>
      <td>isuzu</td>
      <td>std</td>
      <td>7466.792818</td>
    </tr>
    <tr>
      <th>45</th>
      <td>isuzu</td>
      <td>std</td>
      <td>8236.345052</td>
    </tr>
    <tr>
      <th>129</th>
      <td>porsche</td>
      <td>std</td>
      <td>37058.915127</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Well, we can see that: - predictions are ok for audi - predictions are not ok for porsche (because we need more different porsches on training set) - as we don’t have any information for isuzu, maybe would be wise to not predict prices for it.</p>
<p>Thanks,</p>
<p><em>erickfis&#64;gmail.com</em></p>
</div>
</div>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Auto-1 Data Science Challenge</a></li>
<li><a class="reference internal" href="#Part-2---Modeling">Part 2 - Modeling</a><ul>
<li><a class="reference internal" href="#Analysis-of-sample-distribution">Analysis of sample distribution</a><ul>
<li><a class="reference internal" href="#Discussion-about-outliers:">Discussion about outliers:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Balancing-the-data:-bootstrap">Balancing the data: bootstrap</a></li>
<li><a class="reference internal" href="#Fitting-the-models">Fitting the models</a><ul>
<li><a class="reference internal" href="#OLS-with-feature-selection-through-analysis">OLS with feature selection through analysis</a></li>
<li><a class="reference internal" href="#Adjusting-this-model---feature-selection">Adjusting this model - feature selection</a></li>
<li><a class="reference internal" href="#Regularized-models---Ridge">Regularized models - Ridge</a><ul>
<li><a class="reference internal" href="#Normalization">Normalization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Regularized-models---Lasso">Regularized models - Lasso</a></li>
<li><a class="reference internal" href="#Huber-Regressor">Huber Regressor</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Analysis-of-MSE---mean-squared-error">Analysis of MSE - mean squared error</a></li>
<li><a class="reference internal" href="#Analysis-of-variance-explained:-R^2">Analysis of variance explained: <span class="math notranslate nohighlight">\(R^2\)</span></a></li>
<li><a class="reference internal" href="#Residual-analysis">Residual analysis</a><ul>
<li><a class="reference internal" href="#Residual-mean">Residual mean</a></li>
<li><a class="reference internal" href="#Residuals-vs-fitted-values">Residuals vs fitted values</a></li>
<li><a class="reference internal" href="#Testing-residuals-for-normality">Testing residuals for normality</a></li>
<li><a class="reference internal" href="#Correlation-between-residuals-and-features">Correlation between residuals and features</a></li>
<li><a class="reference internal" href="#Correlation-between-residuals-and-\hat-y">Correlation between residuals and <span class="math notranslate nohighlight">\(\hat y\)</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#Fitted-values-distribution-analysis">Fitted values distribution analysis</a></li>
<li><a class="reference internal" href="#Most-important-features">Most important features</a><ul>
<li><a class="reference internal" href="#Ridge">Ridge</a></li>
<li><a class="reference internal" href="#Lasso">Lasso</a></li>
<li><a class="reference internal" href="#OLS">OLS</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Comparing-the-models---conclusions">Comparing the models - conclusions</a></li>
<li><a class="reference internal" href="#Machine-Learning-models">Machine Learning models</a><ul>
<li><a class="reference internal" href="#Decision-Trees">Decision Trees</a></li>
<li><a class="reference internal" href="#Random-Forests">Random Forests</a></li>
<li><a class="reference internal" href="#Gradient-tree-boosting">Gradient tree boosting</a></li>
<li><a class="reference internal" href="#AdaBoost">AdaBoost</a></li>
<li><a class="reference internal" href="#Adding-features">Adding features</a></li>
<li><a class="reference internal" href="#id1">OLS</a></li>
<li><a class="reference internal" href="#id2">Ridge</a></li>
<li><a class="reference internal" href="#Decision-tree">Decision tree</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Final-thoughts">Final thoughts</a></li>
<li><a class="reference internal" href="#Using-the-best-model-for-predicting-NA-prices">Using the best model for predicting NA prices</a></li>
</ul>
</li>
</ul>

  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/auto-1-challenge-part2.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">AutoOne Regression 1.0 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Auto-1 Data Science Challenge</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Erick Medeiros Anastácio.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.1.1.
    </div>
  </body>
</html>